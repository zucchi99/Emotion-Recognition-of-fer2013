{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"emotion_recognition.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import math\n","import seaborn as sea\n","import matplotlib.pyplot as plot\n","import torch\n","from torch.utils.data import TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import ExponentialLR \n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from tqdm.auto import tqdm\n","from datetime import datetime"],"metadata":{"id":"GfUyuvT6ddv_","execution":{"iopub.status.busy":"2021-12-15T19:12:26.307385Z","iopub.execute_input":"2021-12-15T19:12:26.307788Z","iopub.status.idle":"2021-12-15T19:12:28.539533Z","shell.execute_reply.started":"2021-12-15T19:12:26.307680Z","shell.execute_reply":"2021-12-15T19:12:28.538434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount data from drive\n","#from google.colab import drive\n","#drive.mount('/content/drive')"],"metadata":{"id":"WyotH4_nfKZN","execution":{"iopub.status.busy":"2021-12-15T19:12:28.541407Z","iopub.execute_input":"2021-12-15T19:12:28.541849Z","iopub.status.idle":"2021-12-15T19:12:28.545257Z","shell.execute_reply.started":"2021-12-15T19:12:28.541815Z","shell.execute_reply":"2021-12-15T19:12:28.544468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# local path\n","import_dir = ''\n","# francesco drive path\n","#import_dir = '/content/drive/MyDrive/Colab Notebooks/DL/progetto/'\n","# christian drive path\n","#import_dir = '/content/drive/MyDrive/deep_learning/progetto/'\n","\n","export_dir = import_dir + 'output_csv/'\n","\n","#dataset_filename = 'fer2013.\n","dataset_filename = 'fer2021.csv'\n","#set n_features\n","n_features = 3 if (dataset_filename == 'fer2021.csv') else 1\n","\n","dataset_filepath = import_dir + dataset_filename\n","\n","# import dataset colab\n","#data = pd.read_csv(dataset_filepath)"],"metadata":{"id":"Cr3L0treiydL","execution":{"iopub.status.busy":"2021-12-15T19:12:28.546504Z","iopub.execute_input":"2021-12-15T19:12:28.547033Z","iopub.status.idle":"2021-12-15T19:12:28.556330Z","shell.execute_reply.started":"2021-12-15T19:12:28.547001Z","shell.execute_reply":"2021-12-15T19:12:28.555596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#kaggle\n","import_dir = '/kaggle/input/'\n","export_dir = '/kaggle/working/output_csv/'\n","print(os.path.exists(export_dir))\n","if(not os.path.exists(export_dir)) :\n","    os.makedirs(export_dir)\n","print(os.path.exists(export_dir))"],"metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:12:28.558539Z","iopub.execute_input":"2021-12-15T19:12:28.558858Z","iopub.status.idle":"2021-12-15T19:12:28.568022Z","shell.execute_reply.started":"2021-12-15T19:12:28.558825Z","shell.execute_reply":"2021-12-15T19:12:28.567379Z"},"trusted":true,"id":"tkIIVf89G1cy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#kaggle\n","for dirname, _, filenames in os.walk(import_dir):\n","    for filename in filenames :\n","        if(filename == dataset_filename) :\n","            data = pd.read_csv(os.path.join(dirname, filename))"],"metadata":{"execution":{"iopub.status.busy":"2021-12-15T19:12:28.569483Z","iopub.execute_input":"2021-12-15T19:12:28.569739Z","iopub.status.idle":"2021-12-15T19:12:41.233775Z","shell.execute_reply.started":"2021-12-15T19:12:28.569693Z","shell.execute_reply":"2021-12-15T19:12:41.232854Z"},"trusted":true,"id":"r1jPHDurG1cz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data)"],"metadata":{"id":"WT49RKuk4Fnf","execution":{"iopub.status.busy":"2021-12-15T19:12:41.238347Z","iopub.execute_input":"2021-12-15T19:12:41.238618Z","iopub.status.idle":"2021-12-15T19:12:41.258368Z","shell.execute_reply.started":"2021-12-15T19:12:41.238584Z","shell.execute_reply":"2021-12-15T19:12:41.257594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data[\"Usage\"].value_counts())"],"metadata":{"id":"P14R062hBzsy","execution":{"iopub.status.busy":"2021-12-15T19:12:41.262076Z","iopub.execute_input":"2021-12-15T19:12:41.262327Z","iopub.status.idle":"2021-12-15T19:12:41.283025Z","shell.execute_reply.started":"2021-12-15T19:12:41.262295Z","shell.execute_reply":"2021-12-15T19:12:41.282016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#emotions definition and plotting\n","\n","#emozioni = ('rabbia', 'disgusto', 'paura', 'felicit√†',  'tristezza', 'sorpresa', 'neutrale')\n","emotions =  ('rage',   'disgust',  'fear',  'happiness', 'sadness',   'surprise', 'neutral')\n","y = data['emotion']\n","\n","sx = sea.countplot(x=y)\n","plot.xticks(range(len(emotions)), emotions);\n","plot.xlabel(\"Emotions\")\n","plot.ylabel(\"Count\")\n","\n","num_of_emotions = data['emotion'].value_counts().sort_index()\n","print(num_of_emotions)"],"metadata":{"id":"UuTQvRspeAez","execution":{"iopub.status.busy":"2021-12-15T19:12:41.286858Z","iopub.execute_input":"2021-12-15T19:12:41.288848Z","iopub.status.idle":"2021-12-15T19:12:41.651794Z","shell.execute_reply.started":"2021-12-15T19:12:41.288812Z","shell.execute_reply":"2021-12-15T19:12:41.651111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#setting images constants\n","im_h = 48 #height\n","im_l = 48 #length\n","im_d = n_features  #depth"],"metadata":{"id":"uhjfYKKblxED","execution":{"iopub.status.busy":"2021-12-15T19:12:41.652962Z","iopub.execute_input":"2021-12-15T19:12:41.653210Z","iopub.status.idle":"2021-12-15T19:12:41.657551Z","shell.execute_reply.started":"2021-12-15T19:12:41.653176Z","shell.execute_reply":"2021-12-15T19:12:41.656756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#conversione in np-array per guardarlo e in tensor per la rete e li scalo\n","#np-array of Tensor, each\n","\n","def arrToNp(x, shape):\n","    temp = []\n","    for im in tqdm(x):\n","      temp.append(torch.Tensor(np.array(im.split()).reshape(shape).astype('double') / 255))\n","    return temp\n","\n","shape = (im_d,im_h,im_l) if (n_features == 3) else (im_h,im_l,im_d)\n","imgsList = arrToNp(data['pixels'], shape)\n"],"metadata":{"id":"XoWLAraUf9Xk","execution":{"iopub.status.busy":"2021-12-15T19:12:41.660699Z","iopub.execute_input":"2021-12-15T19:12:41.661454Z","iopub.status.idle":"2021-12-15T19:16:01.833722Z","shell.execute_reply.started":"2021-12-15T19:12:41.661407Z","shell.execute_reply":"2021-12-15T19:16:01.833060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#list of Tensor\n","print(type(imgsList))\n","print(len(imgsList))\n","#Tensor 48 x 48\n","print(type(imgsList[0]))\n","print(len(imgsList[0]))"],"metadata":{"id":"UVU5zfYaJYmz","execution":{"iopub.status.busy":"2021-12-15T19:16:01.834842Z","iopub.execute_input":"2021-12-15T19:16:01.835100Z","iopub.status.idle":"2021-12-15T19:16:01.842808Z","shell.execute_reply.started":"2021-12-15T19:16:01.835063Z","shell.execute_reply":"2021-12-15T19:16:01.840963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_image(ima, labelI, val=False, subpl=\"\",title=\"\"):\n","    if subpl==\"\":\n","      plot.imshow((ima).detach().numpy().reshape((48,48)), cmap='gray')\n","      plot.title(emotions[labelI]+ ((\" \"+ str(labelI)) if val else \"\"))\n","    else :\n","      subpl.imshow((ima).detach().numpy().reshape((48,48)), cmap='gray')\n","      subpl.set_title(((\" \"+ str(title)) if title!=\"\" else \"\"))"],"metadata":{"id":"EI_gkcwcoNhc","execution":{"iopub.status.busy":"2021-12-15T19:16:01.844330Z","iopub.execute_input":"2021-12-15T19:16:01.844966Z","iopub.status.idle":"2021-12-15T19:16:01.854097Z","shell.execute_reply.started":"2021-12-15T19:16:01.844927Z","shell.execute_reply":"2021-12-15T19:16:01.853399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seed the pseudorandom number generator\n","from random import seed\n","from random import random\n","# seed random number generator\n","\n","def plot_examples(rows, cols, deterministic=False) :\n","  cur_emot = 0\n","  seed(None)\n","  idx = 0\n","  fig, axs = plot.subplots(rows, cols, figsize=(15,15))\n","  #print_image(imgsList[0], 0, subpl=axs[rows-1][cols-1]) # 1 feature\n","  print_image(imgsList[0][0], 0, subpl=axs[rows-1][cols-1])\n","  fig.delaxes(axs[rows-1,cols-1])\n","  #axs[rows-1,cols-1].set_axis_off()\n","  while (cur_emot < len(emotions)) :\n","    idx = int(random() * len(y)) if not(deterministic) else (idx + 1)\n","    if y[idx] == cur_emot :\n","      plot.figure(cur_emot)\n","      cur_row = cur_emot // cols\n","      cur_col = cur_emot % cols\n","      print_image(imgsList[idx][0], y[idx], title=emotions[cur_emot], subpl=axs[cur_row][cur_col])\n","      #print_image(imgsList[idx], y[idx], title=emotions[cur_emot], subpl=axs[cur_row][cur_col]) # 1 feature\n","      cur_emot += 1\n","\n","plot_examples(2, 4)"],"metadata":{"id":"bsV5Kh3SfdOI","execution":{"iopub.status.busy":"2021-12-15T19:16:01.856465Z","iopub.execute_input":"2021-12-15T19:16:01.857017Z","iopub.status.idle":"2021-12-15T19:16:02.708372Z","shell.execute_reply.started":"2021-12-15T19:16:01.856981Z","shell.execute_reply":"2021-12-15T19:16:02.707622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filterApply(image, filtro, l):\n","  newImage = torch.zeros(image.shape, dtype=image.dtype)\n","  z = w = 0\n","  for x in range(-1,image.shape[0]-l+1,1):\n","    for y in range(-1,image.shape[1]-l+1,1):\n","      for x1 in range(0,l):\n","        for y1 in range(0,l):\n","          newImage[z][w] += filtro(image[x+x1][y+y1] if (x+x1>=0 and y+y1>=0 and x<=image.shape[0]-l and y<=image.shape[1]-l) else 0,x1,y1)\n","      newImage[z][w] /= l*l\n","      w+=1\n","    z+=1\n","    w=0\n","  return newImage"],"metadata":{"id":"nwx3xizCw7Du","execution":{"iopub.status.busy":"2021-12-15T19:16:02.709671Z","iopub.execute_input":"2021-12-15T19:16:02.710288Z","iopub.status.idle":"2021-12-15T19:16:02.719524Z","shell.execute_reply.started":"2021-12-15T19:16:02.710249Z","shell.execute_reply":"2021-12-15T19:16:02.718678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sobol_filter = (lambda i,x,y: ((1-(x%2))*(1+(y%2))*(1-(x%3))*i +(1-(y%2))*(1+(x%2))*(1-(y%3))*i)/2)\n","vertical_filter = (lambda i,x,y: ((1-(y%2))*(1+(x%2))*(1-(y%3))*i))\n","horizontal_filter = (lambda i,x,y: ((1-(x%2))*(1+(y%2))*(1-(x%3))*i))\n","contrast = (lambda i,x,y: (i*i))\n","high_contrast = (lambda i,x,y: (i*i*i))\n","low_contrast = lambda i,x,y: math.sqrt(i)"],"metadata":{"id":"yU4Hahz1PZ0r","execution":{"iopub.status.busy":"2021-12-15T19:16:02.721102Z","iopub.execute_input":"2021-12-15T19:16:02.721858Z","iopub.status.idle":"2021-12-15T19:16:02.734046Z","shell.execute_reply.started":"2021-12-15T19:16:02.721820Z","shell.execute_reply":"2021-12-15T19:16:02.733152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed(None)\n","img_idx = int(random() * len(y))\n","plot.figure(1)\n","fig, axs = plot.subplots(2, 3)\n","print_image(filterApply(imgsList[img_idx][0], horizontal_filter, 3),0,subpl=axs[0,0], title=\"horizontal\")\n","print_image(filterApply(imgsList[img_idx][0], vertical_filter, 3),0,subpl=axs[0,1], title=\"vertical\")\n","print_image(filterApply(imgsList[img_idx][0], sobol_filter, 3),0,subpl=axs[0,2], title=\"sobol\")\n","print_image(filterApply(imgsList[img_idx][0], contrast, 2),0,subpl=axs[1,0], title=\"contrast\")\n","print_image(filterApply(imgsList[img_idx][0], high_contrast, 2),0,subpl=axs[1,1], title=\"high_contrast\")\n","print_image(filterApply(imgsList[img_idx][0], low_contrast, 2),0,subpl=axs[1,2], title=\"low_contrast\")"],"metadata":{"id":"jO1fhIOdy9eM","execution":{"iopub.status.busy":"2021-12-15T19:16:02.737086Z","iopub.execute_input":"2021-12-15T19:16:02.737731Z","iopub.status.idle":"2021-12-15T19:16:05.119652Z","shell.execute_reply.started":"2021-12-15T19:16:02.737676Z","shell.execute_reply":"2021-12-15T19:16:05.118999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else :\n","    device = torch.device('cpu')\n","#device = torch.device('cpu')\n","print(device)"],"metadata":{"id":"605-E3PgGPhM","execution":{"iopub.status.busy":"2021-12-15T19:57:50.208373Z","iopub.execute_input":"2021-12-15T19:57:50.208648Z","iopub.status.idle":"2021-12-15T19:57:50.215468Z","shell.execute_reply.started":"2021-12-15T19:57:50.208617Z","shell.execute_reply":"2021-12-15T19:57:50.214596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = torch.Tensor(y)\n","x = torch.cat((imgsList),0).view(len(imgsList),im_d,im_h,im_l)\n","\n","batch_size  = 32"],"metadata":{"id":"AduV6emE8EJr","execution":{"iopub.status.busy":"2021-12-15T19:57:50.217812Z","iopub.execute_input":"2021-12-15T19:57:50.218519Z","iopub.status.idle":"2021-12-15T19:57:50.840210Z","shell.execute_reply.started":"2021-12-15T19:57:50.218453Z","shell.execute_reply":"2021-12-15T19:57:50.839464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#split random by label (stratify=y)\n","seed(None)\n","split_seed = (int)(random() * 100)\n","split_seed = 99\n","print('split seed:', split_seed)\n","\n","X_train, X_valid_test, y_train, y_valid_test = train_test_split(\n","      x, y, shuffle=True, stratify=y, test_size=0.3, random_state=split_seed)\n","\n","X_test, X_valid, y_test, y_valid = train_test_split(\n","      X_valid_test, y_valid_test, shuffle=True, stratify=y_valid_test, test_size=0.5, random_state=split_seed)"],"metadata":{"id":"ku1rMblo8QkK","execution":{"iopub.status.busy":"2021-12-15T19:57:50.841565Z","iopub.execute_input":"2021-12-15T19:57:50.841820Z","iopub.status.idle":"2021-12-15T19:57:51.614366Z","shell.execute_reply.started":"2021-12-15T19:57:50.841786Z","shell.execute_reply":"2021-12-15T19:57:51.613563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_valid_test_count_df = pd.DataFrame(y_valid_test, columns=['emotion']).value_counts().sort_index()\n","\n","for row in y_valid_test_count_df.iteritems() :\n","  emot = (int)(row[0][0])\n","  count = row[1]\n","  print(emot, count)"],"metadata":{"id":"viPXZZGWOE1m","execution":{"iopub.status.busy":"2021-12-15T19:57:51.615705Z","iopub.execute_input":"2021-12-15T19:57:51.615960Z","iopub.status.idle":"2021-12-15T19:57:51.703041Z","shell.execute_reply.started":"2021-12-15T19:57:51.615925Z","shell.execute_reply":"2021-12-15T19:57:51.702374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = X_train.to(device)\n","X_valid = X_valid.to(device)\n","X_test = X_test.to(device)\n","\n","y_train = y_train.to(device, dtype=torch.long)\n","y_valid = y_valid.to(device, dtype=torch.long)\n","y_test = y_test.to(device, dtype=torch.long)\n","\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","valid_dataset = TensorDataset(X_valid, y_valid)\n","test_dataset = TensorDataset(X_test, y_test)\n","\n","trainloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True)\n","validloader = torch.utils.data.DataLoader(\n","    valid_dataset, batch_size=batch_size, shuffle=True)\n","testloader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"manS8b6hq6u8","execution":{"iopub.status.busy":"2021-12-15T19:57:51.710513Z","iopub.execute_input":"2021-12-15T19:57:51.711812Z","iopub.status.idle":"2021-12-15T19:57:51.968985Z","shell.execute_reply.started":"2021-12-15T19:57:51.711770Z","shell.execute_reply":"2021-12-15T19:57:51.968270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x.size())\n","print(y.size())\n","\n","print(len(trainloader.dataset))\n","print(len(validloader.dataset))\n","print(len(testloader.dataset))"],"metadata":{"id":"qXIY8Q9TDxYw","execution":{"iopub.status.busy":"2021-12-15T19:57:51.970367Z","iopub.execute_input":"2021-12-15T19:57:51.970639Z","iopub.status.idle":"2021-12-15T19:57:51.976658Z","shell.execute_reply.started":"2021-12-15T19:57:51.970605Z","shell.execute_reply":"2021-12-15T19:57:51.975998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DynamicNetInceptions(nn.Module):\n","\n","    def __init__(self, dropout_prob, conv__layer_repetitions=(1,1,1), conv__in_channels=1, conv__out_channels=(6,12,24), lin__out_dimension=(16*7*5,16,len(emotions)), incep__num_layers=4, incep__multiplier=2, im_h=im_h, im_l=im_l) :\n","      super(DynamicNetInceptions, self).__init__()\n","\n","      # PARAMETERS SECTION\n","      self.pool_size = (2,2)\n","      self.kernel_size = (3,3)\n","      self.padding = 1\n","      self.num_of_conv_layers = len(conv__layer_repetitions) # default = 3\n","      self.num_of_lin_layers = len(lin__out_dimension) # default = 3\n","      self.dropout_prob = dropout_prob\n","        \n","      self.dropout = nn.Dropout2d(p=self.dropout_prob)\n","      self.skip = nn.Identity()\n","      \n","      in_chan = conv__in_channels\n","      self.convs = []\n","\n","      if (len(conv__layer_repetitions) != len(conv__out_channels)) :\n","        print(\"ERROR CHECK SIZES!!\")\n","\n","      # CONVOLUTIONAL SECTION\n","      out_chan = 0\n","      for big_layer in range(self.num_of_conv_layers) : # default = 3\n","        out_chan = conv__out_channels[big_layer]\n","        cur_rep_big_layer = conv__layer_repetitions[big_layer]\n","        for repeat_layer in range(cur_rep_big_layer) : #a, b, c, ...\n","          self.convs += [ nn.Conv2d(in_chan, out_chan, self.kernel_size, padding=self.padding) ]\n","          #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","          self.convs += [ nn.ReLU() ]\n","          in_chan = out_chan\n","        self.convs += [ nn.MaxPool2d(self.pool_size) ]\n","\n","      # INCEPTION SECTION\n","      in_chan = out_chan\n","      self.incep__multiplier = incep__multiplier\n","      self.incep__num_layers = incep__num_layers\n","      self.incep_first = self.inception_module(in_chan)\n","      self.incep_after = []\n","      total_out_chan = incep__multiplier*(64 + 128 + 32 + 32) #256 * out_multiplier\n","      in_chan = total_out_chan\n","      for inception_layer in range(incep__num_layers - 1) :\n","          cur_incep = self.inception_module(in_chan)\n","          self.incep_after += [ cur_incep ]\n","\n","      #final output dimension\n","      self.final_conv_dim = total_out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n","\n","      # LINEAR FC SECTION\n","      in_dim = self.final_conv_dim\n","\n","      self.linear_fc = []\n","      for lin_layer in range(self.num_of_lin_layers) :\n","        out_dim = lin__out_dimension[lin_layer]\n","        self.linear_fc += [ nn.Linear(in_dim, out_dim) ]\n","        #self.linear_fc += [ nn.Dropout2d(p=self.dropout_prob) ]\n","        self.linear_fc += [ nn.ReLU() ]\n","        in_dim = out_dim\n","      \n","      # SEQUENTIAL SECTION\n","      self.convs_seq = nn.Sequential(*self.convs).to(device)\n","      self.linear_fc_seq = nn.Sequential(*self.linear_fc).to(device)\n","      self.softmax = nn.Softmax(1).to(device)\n","\n","    def inception_module(self, in_chan, out_1x1=64, out_3x3=[96,128], out_5x5=[16,32], out_pool=32) :\n","      \n","      mul = self.incep__multiplier\n","    \n","      branch_1x1 = nn.Sequential(\n","          nn.Conv2d(in_chan, out_1x1*mul, kernel_size=1) #conv 1x1\n","      ).to(device)\n","\n","      branch_3x3 = nn.Sequential(\n","        nn.Conv2d(in_chan,          (out_3x3[0])*mul, kernel_size=1),           # conv 1x1\n","        nn.Conv2d((out_3x3[0])*mul, (out_3x3[1])*mul, kernel_size=3, padding=1) # conv 3x3\n","      ).to(device)\n","\n","      branch_5x5 =  nn.Sequential(\n","        nn.Conv2d(in_chan,          (out_5x5[0])*mul, kernel_size=1),           # conv 1x1\n","        nn.Conv2d((out_5x5[0])*mul, (out_5x5[1])*mul, kernel_size=5, padding=2) # conv 5x5\n","      ).to(device)\n","\n","      branch_pool =  nn.Sequential(\n","        nn.MaxPool2d(kernel_size=3, stride=1, padding=0), # max_pool 3x3\n","        nn.Conv2d(in_chan, out_pool*mul, kernel_size=1, stride=1, padding=1) # conv 1x1\n","      ).to(device)\n","        \n","      return [ branch_1x1, branch_3x3, branch_5x5, branch_pool ]\n","\n","    def print_net(self) :\n","      print(\"__Convolutionals Start__\")\n","      print(self.convs_seq)\n","      print(\"__Convolutionals End__\")\n","      print(self.dropout)\n","      print(\"__Inception Start (with skip)__\")\n","      print(\"Inception__1 with dim: N -> (256 * mul)\")\n","      print(self.incep_first)\n","      print(f\"Inception__2,...,{self.incep__num_layers} with dim: (256 * mul) -> (256 * mul)\")\n","      print(self.incep_after[0])\n","      print(\"__Inception End__\")\n","      #if (self.incep__num_layers > 0) :\n","      #    print(\"__Inception Start (with skip)__\")\n","      #    print(\"Inception__0:\")\n","      #    print(self.incep_first)\n","      #    for i in range(self.incep__num_layers - 1) :\n","      #        print(f\"Inception__{i+1}\")\n","      #        print(self.incep_after[i])\n","      #    print(\"__Inception End__\")\n","      #print(f\"Channel concat: torch.cat(branches)\")\n","      print(self.dropout)\n","      print(f\"Reshape(-1, {self.final_conv_dim})\")\n","      print(\"__Linear Start__\")\n","      print(self.linear_fc_seq)\n","      print(\"__Linear End__\")\n","      print(self.softmax)\n","\n","    def run_inception(self, x, inception) :\n","      x_1x1  = (inception[0])(x)\n","      x_3x3  = (inception[1])(x)\n","      x_5x5  = (inception[2])(x)\n","      x_pool = (inception[3])(x)\n","      concat = torch.cat((x_1x1, x_3x3, x_5x5, x_pool), 1)\n","      return concat\n","    \n","    def forward(self, x):\n","\n","      #print(x.size())\n","      x = self.convs_seq(x)\n","    \n","      x = self.dropout(x)\n","        \n","      #print(\"after convs\", x.size())\n","      if (self.incep__num_layers > 0) :\n","        x = self.run_inception(x, self.incep_first) \n","        #print(\"after first\", x.size()) \n","        for inception in self.incep_after : \n","          x = self.run_inception(x, inception) + self.skip(x)\n","          #print(\"after ith inception\",x.size())\n","\n","      x = self.dropout(x)\n","    \n","      x = x.reshape(-1, self.final_conv_dim)\n","      #print(x.size())\n","      \n","      x = self.linear_fc_seq(x)\n","      \n","      x = self.softmax(x)\n","\n","      return x\n","\n","net = DynamicNetInceptions(0.1,conv__layer_repetitions=(2,2,1), conv__in_channels=3)\n","net.print_net()"],"metadata":{"id":"BkJpt-vvdr1M","execution":{"iopub.status.busy":"2021-12-15T19:57:52.055467Z","iopub.execute_input":"2021-12-15T19:57:52.055744Z","iopub.status.idle":"2021-12-15T19:57:52.211743Z","shell.execute_reply.started":"2021-12-15T19:57:52.055693Z","shell.execute_reply":"2021-12-15T19:57:52.210283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DynamicNetBasic(nn.Module):\n","\n","    def __init__(self, dropout_prob, conv__layer_repetitions=(1,1,1), conv__in_channels=1, conv__out_channels=(6,12,24), lin__out_dimension=(16*7*5,16,len(emotions)), im_h=im_h, im_l=im_l) :\n","      super(DynamicNetBasic, self).__init__()\n","\n","      #params\n","      self.pool_size = (2,2)\n","      self.kernel_size = (3,3)\n","      self.padding = 1\n","      self.num_of_conv_layers = len(conv__layer_repetitions) # default = 3\n","      self.num_of_lin_layers = len(lin__out_dimension) # default = 3\n","      self.dropout_prob = dropout_prob\n","      \n","      in_chan = conv__in_channels\n","      self.convs = [] \n","\n","      if (len(conv__layer_repetitions) != len(conv__out_channels)) :\n","        print(\"ERROR\")\n","\n","      for big_layer in range(self.num_of_conv_layers) : # default = 3\n","        out_chan = conv__out_channels[big_layer]\n","        cur_rep_big_layer = conv__layer_repetitions[big_layer]\n","        for repeat_layer in range(cur_rep_big_layer) : #a, b, c, ...\n","          self.convs += [ nn.Conv2d(in_chan, out_chan, self.kernel_size, padding=self.padding) ]\n","          #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","          self.convs += [ nn.ReLU() ]\n","          in_chan = out_chan\n","        self.convs += [nn.MaxPool2d(self.pool_size)]\n","\n","      self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","      \n","      #final output dimension\n","      self.final_conv_dim = out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n","\n","      # linears\n","      in_dim = self.final_conv_dim\n","\n","      self.linear_fc = []\n","      for lin_layer in range(self.num_of_lin_layers) :\n","        out_dim = lin__out_dimension[lin_layer]\n","        self.linear_fc += [ nn.Linear(in_dim, out_dim) ]\n","        #self.linear_fc += [ nn.Dropout2d(p=self.dropout_prob) ]\n","        self.linear_fc += [ nn.ReLU() ]\n","        in_dim = out_dim\n","      \n","      self.softmax = nn.Softmax(1)\n","\n","      self.features = nn.Sequential(*self.convs).to(device)\n","      self.linear_fc = nn.Sequential(*self.linear_fc).to(device)\n","\n","      #print(self.features)\n","      #print(self.linear_fc)\n","\n","    def print_net(self) :\n","      print(self.features)\n","      print(f\"Reshape(-1, {self.final_conv_dim})\")\n","      print(self.linear_fc)\n","      print(self.softmax)\n","\n","    def forward(self, x):\n","      \n","      x = self.features(x)\n","      x = x.reshape(-1, self.final_conv_dim)\n","      x = self.linear_fc(x)\n","      \n","      x = self.softmax(x)\n","\n","      return x\n","\n","net = DynamicNetBasic(0.1,conv__layer_repetitions=(2,2,1), conv__in_channels=3)\n","net.print_net()"],"metadata":{"id":"jbroYNSnQqYU","execution":{"iopub.status.busy":"2021-12-15T19:57:52.214567Z","iopub.execute_input":"2021-12-15T19:57:52.214776Z","iopub.status.idle":"2021-12-15T19:57:52.240479Z","shell.execute_reply.started":"2021-12-15T19:57:52.214751Z","shell.execute_reply":"2021-12-15T19:57:52.239630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DynamicNet(nn.Module):\n","    def __init__(self, dropout_prob, a=1, b=1, c=1, in_channels=1, im_h=im_h, im_l=im_l) :\n","      super(DynamicNet, self).__init__()\n","\n","      #params\n","      self.pool_size = (2,2)\n","      self.kernel_size = (3,3)\n","      self.padding = 1\n","      self.num_of_conv_layers = 3\n","      self.dropout_prob = dropout_prob\n","\n","      #convolutionals\n","      in_chan = in_channels\n","      out_chan = 6\n","      self.conv2D = [nn.Conv2d(in_channels, out_chan, self.kernel_size, padding=self.padding), nn.ReLU() ]\n","      self.conv2D += [(nn.Conv2d(out_chan, out_chan, self.kernel_size, padding=self.padding), nn.ReLU()) for i in range(a-1)]\n","      self.conv2D += [nn.MaxPool2d(self.pool_size)]\n","\n","      in_chan = out_chan\n","      out_chan = out_chan * 2\n","      self.conv2D += [(nn.Conv2d(in_chan,out_chan,self.kernel_size, padding=self.padding)), nn.ReLU()]\n","      self.conv2D += [(nn.Conv2d(out_chan,out_chan,self.kernel_size, padding=self.padding), nn.ReLU()) for i in range(b-1)]\n","      self.conv2D += [nn.MaxPool2d(self.pool_size)]\n","\n","      in_chan = out_chan\n","      out_chan = out_chan * 2\n","      self.conv2D += [(nn.Conv2d(in_chan,out_chan,self.kernel_size, padding=self.padding)), nn.ReLU()]\n","      self.conv2D += [(nn.Conv2d(out_chan,out_chan,self.kernel_size, padding=self.padding), nn.ReLU()) for i in range(c-1)]\n","      self.conv2D += [nn.MaxPool2d(self.pool_size)]\n"," \n","      #final output dimension\n","      self.final_conv_dim = out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n","\n","      # linears\n","      in_dim = self.final_conv_dim\n","      out_dim = 16*7*5\n","      self.linear_fc  =  [nn.Linear(in_dim, out_dim), nn.ReLU()]\n","\n","      for layer in self.conv2D :\n","        print(layer)\n","\n","      in_dim = out_dim\n","      out_dim = 16\n","      self.linear_fc +=  [nn.Linear(in_dim, out_dim), nn.ReLU()]\n","\n","      in_dim = out_dim\n","      out_dim = len(emotions)\n","      self.linear_fc +=  [nn.Linear(in_dim, out_dim), nn.ReLU()]\n","      \n","      self.features = nn.Sequential(*self.conv2D)\n","      self.linear_fc = nn.Sequential(*self.linear_fc)\n","\n","    def forward(self, x):\n","\n","      x = self.features(x)\n","      x = x.reshape(-1, self.final_conv_dim)\n","      x = self.linear_fc(x) # RuntimeError: shape '[-1, 17150]' is invalid for input of size 82688\n","\n","      return x\n","\n","net = DynamicNet(0.1)"],"metadata":{"id":"3cYjYLVwmqJt","execution":{"iopub.status.busy":"2021-12-15T19:57:52.243419Z","iopub.execute_input":"2021-12-15T19:57:52.243607Z","iopub.status.idle":"2021-12-15T19:57:52.269446Z","shell.execute_reply.started":"2021-12-15T19:57:52.243583Z","shell.execute_reply":"2021-12-15T19:57:52.268765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Optimization:\n","    def __init__(self, model, loss_fn, optimizer, scheduler=None):\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","    \n","    def count_preds_correct(self, y_pred, y) :\n","      preds = torch.argmax(y_pred, axis=1)\n","      count = preds.eq(y.data.view_as(preds)).cpu().sum()\n","      #print(count, preds.size(), y.size())\n","      #for i in range(preds.size()[0]) :\n","      #      print(preds[i], y[i], preds[i].eq(y[i].data.view_as(preds[i])).cpu())\n","      #print(\"end\")\n","      return count\n","    \n","    def train_step(self, x, y):\n","        #count correct predictions\n","        preds_correct = 0\n","        # Set training mode\n","        self.model.train()\n","        # Predict\n","        y_pred = self.model(x)\n","        # Computes loss, gradients\n","        #print(y.size(), y_pred.size())\n","        loss = self.loss_fn(y_pred, y)\n","        loss.backward()\n","        # Updates parameters, set to zero gradients\n","        self.optimizer.step()\n","        self.optimizer.zero_grad()\n","        # Return loss, num of correct predictions\n","        x = self.count_preds_correct(y_pred, y)\n","        preds_correct += x\n","        return loss.item(), preds_correct\n","    \n","    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1, im_h=48, im_l=48):\n","        for epoch in range(n_epochs + 1):\n","            #print(f\"epoch: {epoch}\")\n","            batch_train_losses = []\n","            batch_train_accs = []\n","            train_i = 0\n","            val_i = 0\n","            train_correct = 0\n","            val_correct = 0\n","            \n","            #for x in train_loader.dataset.tensors :\n","              #print(type(x), x.get_device()) # CUDA -> 0, CPU -> -1\n","\n","            #print(\"training\")\n","            for idx, batch in enumerate(train_loader):\n","                x_batch, y_batch = batch        \n","                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","\n","                #now = datetime.now().strftime(\"%H:%M:%S\")\n","                #print(f\"{now} epoch: {epoch}, train_i: {train_i}, val_i: {val_i}\")\n","                #x_batch = x_batch.view([cur_batch_size, -1, n_features]).to(device)\n","                cur_batch_size = len(x_batch)\n","                x_batch = x_batch.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n","                y_batch = y_batch.to(device)\n","                #print(x_batch.get_device(), y_batch.get_device())\n","                #print(f\"x_batch.size: {x_batch.size()}, y_val: {y_batch.size()}\")\n","                #cur_train_correct = 0\n","                loss, train_correct = self.train_step(x_batch, y_batch)\n","                batch_train_accs.append(train_correct / cur_batch_size)\n","                batch_train_losses.append(loss)\n","                train_i = train_i + 1\n","            train_acc = np.mean(batch_train_accs)\n","            train_loss = np.mean(batch_train_losses)\n","            self.train_accuracies.append(train_acc)\n","            self.train_losses.append(train_loss)\n","            if (self.scheduler) is not None:\n","              self.scheduler.step()\n","  \n","            #print(\"validation\")\n","            with torch.no_grad():\n","                batch_val_losses = []\n","                batch_val_accs = []\n","                for x_val, y_val in val_loader:\n","                    #now = datetime.now().strftime(\"%H:%M:%S\")\n","                    #print(f\"{now} epoch: {epoch}, train_i: {train_i}, val_i: {val_i}\")\n","                    cur_batch_size = len(x_val)\n","                    #print(f\"len(x_val): {cur_batch_size}\")\n","                    #x_val = x_val.view([cur_batch_size, -1, n_features]).to(device)\n","                    x_val = x_val.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n","                    y_val = y_val.to(device)\n","                    #print(f\"x_val.size: {x_val.size()}, y_val: {y_val.size()}\")\n","                    self.model.eval()\n","                    y_pred = self.model(x_val)\n","                    val_correct = self.count_preds_correct(y_pred, y_val)\n","                    val_loss = self.loss_fn(y_pred, y_val).item()\n","                    batch_val_acc_cur = (val_correct / cur_batch_size)\n","                    #print(val_correct, cur_batch_size, batch_val_acc_cur)\n","                    batch_val_accs.append(batch_val_acc_cur)\n","                    batch_val_losses.append(val_loss)\n","                    val_i = val_i + 1\n","                val_acc = np.mean(batch_val_accs)\n","                val_loss = np.mean(batch_val_losses)\n","                self.val_accuracies.append(val_acc)\n","                self.val_losses.append(val_loss)\n","\n","            if (epoch % 1 == 0):\n","                now = datetime.now().strftime(\"%H:%M:%S\")\n","                print(f\"{now} [{epoch:2d}/{n_epochs}] Train: [ loss: {train_loss:.8f}, acc: {train_acc:.8f} ] \\t Validation: [ loss: {val_loss:.8f}, acc: {val_acc:.8f} ]\")\n","\n","        return self.model.state_dict()\n","\n","    def evaluate(self, test_loader, batch_size=1, n_features=1, im_h=48, im_l=48):\n","        #print(\"testing\")\n","        with torch.no_grad():\n","            predictions = []\n","            real_values = []\n","            for x_test, y_test in test_loader:\n","                cur_batch_size = len(x_test)\n","                #x_test = x_test.view([cur_batch_size, -1, n_features]).to(device)\n","                x_test = x_test.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n","                y_test = y_test.to(device)\n","                self.model.eval()\n","                y_pred = self.model(x_test)\n","                predictions.append(y_pred.to('cpu').detach().numpy())\n","                real_values.append(y_test.to('cpu').detach().numpy())\n","\n","        return predictions, real_values      \n","\n","    def plot_losses(self):\n","        plot.plot(self.train_losses, label=\"Training loss\")\n","        plot.plot(self.val_losses, label=\"Validation loss\")\n","        plot.legend()\n","        plot.title(\"Evolution of losses over time\")\n","        plot.xlabel(\"Epochs\")\n","        plot.ylabel(\"Losses\")\n","        plot.show()\n","        plot.close()\n","\n","    def plot_accuracies(self):\n","        plot.plot(self.train_accuracies, label=\"Training accuracy\")\n","        plot.plot(self.val_accuracies, label=\"Validation accuracy\")\n","        plot.legend()\n","        plot.title(\"Evolution of accuracies over time\")\n","        plot.xlabel(\"Epochs\")\n","        plot.ylabel(\"Accuracies\")\n","        plot.show()\n","        plot.close()\n","  \n","    def plot_losses_accuracies(self, figsize=(12,4)):\n","        fig, axs = plot.subplots(1, 2, figsize=figsize)\n","        #losses\n","        plot_1 = axs[0]\n","        plot_1.plot(self.train_losses, label=\"Training loss\")\n","        plot_1.plot(self.val_losses, label=\"Validation loss\")\n","        plot_1.legend()\n","        plot_1.set_title(\"Evolution of losses over time\")\n","        plot_1.set_xlabel(\"Epochs\")\n","        plot_1.set_ylabel(\"Losses\")\n","        #accuracies\n","        plot_2 = axs[1]\n","        plot_2.plot(self.train_accuracies, label=\"Training accuracy\")\n","        plot_2.plot(self.val_accuracies, label=\"Validation accuracy\")\n","        plot_2.legend()\n","        plot_2.set_title(\"Evolution of accuracies over time\")\n","        plot_2.set_xlabel(\"Epochs\")\n","        plot_2.set_ylabel(\"Accuracies\")\n","        "],"metadata":{"id":"mHdagsNmyFKL","execution":{"iopub.status.busy":"2021-12-15T19:57:52.322119Z","iopub.execute_input":"2021-12-15T19:57:52.322323Z","iopub.status.idle":"2021-12-15T19:57:52.353134Z","shell.execute_reply.started":"2021-12-15T19:57:52.322299Z","shell.execute_reply":"2021-12-15T19:57:52.352427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#R1 NO INCEPTION:\n","#n_epochs = 40\n","#learning_rate = 5e-5\n","#weight_decay = 1e-9\n","#dropout_prob = 0.35\n","#n_features=3\n","\n","#dynamic net parameters\n","#conv part:\n","#conv__in_channels=3\n","#conv__out_channels=(288,566,1122,2244)\n","#conv__layer_repetitions=(4,3,2,1) #a=3, b=2, c=1\n","#linear part:\n","#lin__out_dimension=(1024,356,158,64,len(emotions)"],"metadata":{"id":"NgcrNXxDorAR","execution":{"iopub.status.busy":"2021-12-15T19:57:52.370951Z","iopub.execute_input":"2021-12-15T19:57:52.371370Z","iopub.status.idle":"2021-12-15T19:57:52.378437Z","shell.execute_reply.started":"2021-12-15T19:57:52.371332Z","shell.execute_reply":"2021-12-15T19:57:52.377653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#R2 YES INCEPTION:\n","n_epochs = 30\n","learning_rate = 1e-4\n","weight_decay = 1e-8\n","dropout_prob = 0.62\n","\n","#dynamic net parameters\n","#conv part:\n","conv__in_channels=n_features     #num_of_channels in dataset = 3: original, \n","conv__out_channels=     (200,400,600,800) #out channels of each conv\n","conv__layer_repetitions=(  2,  2,  2,  1) #number of repetitions of i-th conv before go to next one, first has channels (N-1 -> N), others (N -> N)\n","#linear part:\n","lin__out_dimension=(432, 108, 27, len(emotions)) #out dimension of fc, last one = 7\n","#inception part:\n","incep__num_layers=30 #num of inspection modules, NB the first has shape (N -> 256*mul), others (256*mul -> 256*mul)\n","incep__multiplier=3  #multiplier of the default out dim of resnet: (64 for 1x1, 128 per 3x3, 32 per 5x5, 32 per maxpool)\n","#NB: reshape = 256 * incep__multiplier * ((48 // (2 ** num_of_conv_layers)) ** 2) = 6912 (if mul=3, layers=4)\n","\n","model = DynamicNetInceptions(dropout_prob, conv__layer_repetitions, conv__in_channels, conv__out_channels, lin__out_dimension, incep__num_layers, incep__multiplier)\n","#model = DynamicNetBasic(dropout_prob, conv__layer_repetitions, conv__in_channels, conv__out_channels, lin__out_dimension)\n","next(model.parameters()).device\n","model.print_net()\n","\n","loss_fn = torch.nn.CrossEntropyLoss(reduction='sum') \n","#loss_fn = torch.nn.KLDivLoss(reduction='sum') \n","#loss_fn = torch.nn.NLLLoss(reduction='sum')\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","#optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n","scheduler = ExponentialLR(optimizer, gamma=0.9)\n","#scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n","#train\n","opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n","model_state_dict = opt.train(trainloader, validloader, batch_size=batch_size, n_epochs=n_epochs, n_features=3)\n","opt.plot_losses_accuracies() \n","#test\n","y_pred_numpy, y_test_numpy = opt.evaluate(testloader, batch_size=1, n_features=n_features)"],"metadata":{"id":"pF8gbnsVybcB","execution":{"iopub.status.busy":"2021-12-15T19:57:52.379970Z","iopub.execute_input":"2021-12-15T19:57:52.380250Z","iopub.status.idle":"2021-12-15T20:50:39.808525Z","shell.execute_reply.started":"2021-12-15T19:57:52.380198Z","shell.execute_reply":"2021-12-15T20:50:39.807793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def flat_list(main_list):\n","    return [item for sub_list in main_list for item in sub_list]\n","\n","#remove batch divisions, get only predn_featuress\n","y_pred_list = [ np.argmax(item) for item in flat_list(y_pred_numpy)]\n","y_test_list = flat_list(y_test_numpy)\n","\n","num_of_emotions = len(emotions)\n","true_preds  = [ 0 for _ in range(num_of_emotions) ]\n","false_preds = [ 0 for _ in range(num_of_emotions) ]\n","\n","for i in range(len(y_test_list)) :\n","  emot_pred = y_pred_list[i]\n","  emot_real = y_test_list[i]\n","  if emot_pred == emot_real :\n","    true_preds[emot_real] += 1\n","  else :\n","    false_preds[emot_real] += 1\n","\n","accuracy = [ (true_preds[i] / (true_preds[i] + false_preds[i])) for i in range(num_of_emotions) ]\n","total_approx_acc = np.mean(accuracy)\n","total_true = np.sum(true_preds)\n","total_false = np.sum(false_preds)\n","total_real_acc = total_true / (total_true + total_false)\n","\n","analysis_df = pd.DataFrame(\n","    list(zip(list(emotions), true_preds, false_preds, accuracy)), \n","    columns=['emotions', 'true_preds', 'false_preds', 'accuracy']\n",")\n","print(f\"{total_approx_acc:.5f} mean of accuracy of each label\")\n","print(f\"{total_real_acc:.5f} accuracy of all test set\")\n","print(analysis_df)"],"metadata":{"id":"GWB9LNDsVYYs","execution":{"iopub.status.busy":"2021-12-15T20:50:39.809927Z","iopub.execute_input":"2021-12-15T20:50:39.810366Z","iopub.status.idle":"2021-12-15T20:50:39.847877Z","shell.execute_reply.started":"2021-12-15T20:50:39.810326Z","shell.execute_reply":"2021-12-15T20:50:39.847149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# store y_pred, y_real to df\n","y_pred_real_df = pd.DataFrame(\n","    list(zip(y_pred_list, y_test_list)), \n","    columns=['y_pred_list', 'y_test_list']\n",")\n","print(y_pred_real_df)"],"metadata":{"execution":{"iopub.status.busy":"2021-12-15T20:50:39.849113Z","iopub.execute_input":"2021-12-15T20:50:39.849473Z","iopub.status.idle":"2021-12-15T20:50:39.866677Z","shell.execute_reply.started":"2021-12-15T20:50:39.849431Z","shell.execute_reply":"2021-12-15T20:50:39.865996Z"},"trusted":true,"id":"sl4FmZPuG1dG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# store parameters to df\n","params_dict = {\n","    'n_epochs':                 [n_epochs],\n","    'learning_rate':            [learning_rate],\n","    'weight_decay':             [weight_decay],\n","    'dropout_prob':             [dropout_prob],\n","    'conv__in_channels':        [conv__in_channels],\n","    'conv__out_channels':       [conv__out_channels],\n","    'conv__layer_repetitions':  [conv__layer_repetitions],\n","    'lin__out_dimension':       [lin__out_dimension],\n","    'loss_fn':                  [loss_fn],\n","    'optimizer':                [optimizer.__class__.__name__],\n","    'split_seed':               [split_seed],\n","    'incep__num_layers':        [incep__num_layers],\n","    'incep__multiplier':        [incep__multiplier]\n","}\n","\n","params_df = pd.DataFrame(params_dict)\n","print(params_df)"],"metadata":{"id":"G8L65IdIZj3d","execution":{"iopub.status.busy":"2021-12-15T20:50:39.867631Z","iopub.execute_input":"2021-12-15T20:50:39.867876Z","iopub.status.idle":"2021-12-15T20:50:39.883935Z","shell.execute_reply.started":"2021-12-15T20:50:39.867851Z","shell.execute_reply":"2021-12-15T20:50:39.883246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# store losses and accuracies to df\n","losses_accuracies_df = pd.DataFrame(\n","    list(zip(opt.train_losses, opt.val_losses, opt.train_accuracies, opt.val_accuracies)),\n","    columns=['train_losses', 'val_losses', 'train_accuracies', 'val_accuracies']\n",")\n","print(losses_accuracies_df)"],"metadata":{"id":"TE8sq69NkEj0","execution":{"iopub.status.busy":"2021-12-15T20:50:39.885058Z","iopub.execute_input":"2021-12-15T20:50:39.885857Z","iopub.status.idle":"2021-12-15T20:50:39.898490Z","shell.execute_reply.started":"2021-12-15T20:50:39.885818Z","shell.execute_reply":"2021-12-15T20:50:39.896958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scikitplot\n","scikitplot.metrics.plot_confusion_matrix(y_pred_list, y_test_list, figsize=(7,7))\n","plot.savefig(\"confusion_matrix.png\")"],"metadata":{"execution":{"iopub.status.busy":"2021-12-15T20:53:34.997091Z","iopub.execute_input":"2021-12-15T20:53:34.997359Z","iopub.status.idle":"2021-12-15T20:53:35.594682Z","shell.execute_reply.started":"2021-12-15T20:53:34.997330Z","shell.execute_reply":"2021-12-15T20:53:35.594016Z"},"trusted":true,"id":"cOCXANlHG1dG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#export parameters, analysis to csv file\n","now = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n","extension = '.csv'\n","\n","to_export = {\n","    \"_y_pred_real_\":       y_pred_real_df,\n","    \"_params_\" :           params_df,\n","    \"_analysis_\":          analysis_df,\n","    \"_losses_accuracies_\": losses_accuracies_df\n","}\n","\n","for name_cur, df_cur in to_export.items() :\n","    filename = (export_dir + now + name_cur + extension)\n","    df_cur.to_csv(filename, sep=';')"],"metadata":{"id":"nKnQ5ZnIevrG","execution":{"iopub.status.busy":"2021-12-15T20:50:39.899902Z","iopub.execute_input":"2021-12-15T20:50:39.900223Z","iopub.status.idle":"2021-12-15T20:50:39.922387Z","shell.execute_reply.started":"2021-12-15T20:50:39.900168Z","shell.execute_reply":"2021-12-15T20:50:39.921773Z"},"trusted":true},"execution_count":null,"outputs":[]}]}