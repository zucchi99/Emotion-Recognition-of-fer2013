{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport math\nfrom random import seed\nfrom random import random\nimport seaborn as sea\nimport matplotlib.pyplot as plot\nimport torch\nfrom torch.utils.data import TensorDataset\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nfrom datetime import datetime","metadata":{"id":"GfUyuvT6ddv_","execution":{"iopub.status.busy":"2021-12-22T16:14:47.730187Z","iopub.execute_input":"2021-12-22T16:14:47.730664Z","iopub.status.idle":"2021-12-22T16:14:49.827839Z","shell.execute_reply.started":"2021-12-22T16:14:47.730534Z","shell.execute_reply":"2021-12-22T16:14:49.827282Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset_filename = 'fer2013_augmented_v3.csv'\n#image sizes\nim_l = 48\nim_h = 48","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:14:49.829202Z","iopub.execute_input":"2021-12-22T16:14:49.829584Z","iopub.status.idle":"2021-12-22T16:14:49.833779Z","shell.execute_reply.started":"2021-12-22T16:14:49.829549Z","shell.execute_reply":"2021-12-22T16:14:49.833233Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#can_be_computed = [ 'local', 'colab', 'kaggle' ]\nactually_computed = 'kaggle'","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:14:49.834573Z","iopub.execute_input":"2021-12-22T16:14:49.835151Z","iopub.status.idle":"2021-12-22T16:14:49.843814Z","shell.execute_reply.started":"2021-12-22T16:14:49.835108Z","shell.execute_reply":"2021-12-22T16:14:49.842970Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# for local\n# --------------------------------------------\nif (actually_computed == 'local') :\n    import_dir = ''\n    export_dir = 'output_csv/'","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:14:49.844877Z","iopub.execute_input":"2021-12-22T16:14:49.845080Z","iopub.status.idle":"2021-12-22T16:14:49.855151Z","shell.execute_reply.started":"2021-12-22T16:14:49.845052Z","shell.execute_reply":"2021-12-22T16:14:49.854471Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# for google colab \n# --------------------------------------------\nif (actually_computed == 'colab') :\n    import_dir = '/content/drive/MyDrive/Colab Notebooks/DL/progetto/'\n    export_dir = import_dir + 'output_csv/'\n\n    # Mount data from drive\n    from google.colab import drive\n    drive.mount('/content/drive')","metadata":{"id":"WyotH4_nfKZN","execution":{"iopub.status.busy":"2021-12-22T16:14:49.857306Z","iopub.execute_input":"2021-12-22T16:14:49.857538Z","iopub.status.idle":"2021-12-22T16:14:49.866676Z","shell.execute_reply.started":"2021-12-22T16:14:49.857511Z","shell.execute_reply":"2021-12-22T16:14:49.866085Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# for kaggle\n# --------------------------------------------\nif (actually_computed == 'kaggle') :\n    import_dir = '/kaggle/input/fer2013-v3/'\n    export_dir = '/kaggle/working/output_csv/'\n\n    if(not os.path.exists(export_dir)) :\n        os.makedirs(export_dir)\n    print(os.path.exists(export_dir))","metadata":{"id":"Cr3L0treiydL","execution":{"iopub.status.busy":"2021-12-22T16:14:49.867532Z","iopub.execute_input":"2021-12-22T16:14:49.868127Z","iopub.status.idle":"2021-12-22T16:14:49.878877Z","shell.execute_reply.started":"2021-12-22T16:14:49.868094Z","shell.execute_reply":"2021-12-22T16:14:49.878180Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dataset_filepath = import_dir + dataset_filename\nprint(f\"reading dataset: {dataset_filepath}\")\ndata = pd.read_csv(dataset_filepath)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:14:49.880106Z","iopub.execute_input":"2021-12-22T16:14:49.880486Z","iopub.status.idle":"2021-12-22T16:16:03.824603Z","shell.execute_reply.started":"2021-12-22T16:14:49.880446Z","shell.execute_reply":"2021-12-22T16:16:03.823827Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"drop_columns = ['emotion', 'Usage' ]\nused_columns = set(data.columns) - set(drop_columns)\nprint(used_columns)\nim_d = n_features = len(used_columns)\nprint(im_d)\nlen_dataset = len(data)\nprint(len_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:16:03.825666Z","iopub.execute_input":"2021-12-22T16:16:03.825873Z","iopub.status.idle":"2021-12-22T16:16:03.833730Z","shell.execute_reply.started":"2021-12-22T16:16:03.825847Z","shell.execute_reply":"2021-12-22T16:16:03.832031Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#print the TRANSPOSE of a random row\nseed(None)\nimg_idx = int(random() * len_dataset)\nprint('img_idx:', img_idx)\n#random row in dataset:\nprint(data[img_idx:img_idx+1].T)","metadata":{"id":"WT49RKuk4Fnf","execution":{"iopub.status.busy":"2021-12-22T16:16:03.834928Z","iopub.execute_input":"2021-12-22T16:16:03.835328Z","iopub.status.idle":"2021-12-22T16:16:03.852534Z","shell.execute_reply.started":"2021-12-22T16:16:03.835294Z","shell.execute_reply":"2021-12-22T16:16:03.851615Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(data[\"Usage\"].value_counts())","metadata":{"id":"P14R062hBzsy","execution":{"iopub.status.busy":"2021-12-22T16:16:03.853924Z","iopub.execute_input":"2021-12-22T16:16:03.854969Z","iopub.status.idle":"2021-12-22T16:16:03.870053Z","shell.execute_reply.started":"2021-12-22T16:16:03.854927Z","shell.execute_reply":"2021-12-22T16:16:03.869179Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#emotions definition and plotting\n\n#emozioni = ('rabbia', 'disgusto', 'paura', 'felicit√†',  'tristezza', 'sorpresa', 'neutrale')\nemotions =  ('rage',   'disgust',  'fear',  'happiness', 'sadness',   'surprise', 'neutral')\ny = data['emotion']\n\nsx = sea.countplot(x=y)\nplot.xticks(range(len(emotions)), emotions)\nplot.xlabel(\"Emotions\")\nplot.ylabel(\"Count\")\n\nnum_of_emotions = data['emotion'].value_counts().sort_index()\nprint(num_of_emotions)","metadata":{"id":"UuTQvRspeAez","execution":{"iopub.status.busy":"2021-12-22T16:16:03.871096Z","iopub.execute_input":"2021-12-22T16:16:03.871868Z","iopub.status.idle":"2021-12-22T16:16:04.245484Z","shell.execute_reply.started":"2021-12-22T16:16:03.871823Z","shell.execute_reply":"2021-12-22T16:16:04.244667Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def split_image_pixels(df, im_d=im_d, im_h=im_h, im_l=im_l):\n    dataset = []\n    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n        image = []\n        for im in row :\n            image.append(np.array(im.split()))\n        dataset.append(np.array(image).reshape(im_d, im_h, im_l).astype('int32'))\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:17:20.812685Z","iopub.execute_input":"2021-12-22T16:17:20.813160Z","iopub.status.idle":"2021-12-22T16:17:20.818966Z","shell.execute_reply.started":"2021-12-22T16:17:20.813128Z","shell.execute_reply":"2021-12-22T16:17:20.818398Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#on kaggle with GPU enabled: it will take about 15 minutes (14 GB CPU RAM, 16 GB GPU RAM)\n#splitted in two parts to not exceed memory\n\nimages = split_image_pixels(data.drop(columns=drop_columns))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:17:23.198924Z","iopub.execute_input":"2021-12-22T16:17:23.199582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_image(np_image, title, im_l=im_l, im_h=im_h):\n    plot.imshow(np_image, cmap = 'gray')\n    plot.title(str(title))\n        \ndef print_sub_image(np_image, title, subpl, im_l=im_l, im_h=im_h):\n    subpl.imshow(np_image, cmap = 'gray')\n    subpl.set_title(str(title))","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:16:41.773016Z","iopub.status.idle":"2021-12-22T16:16:41.773337Z","shell.execute_reply.started":"2021-12-22T16:16:41.773181Z","shell.execute_reply":"2021-12-22T16:16:41.773197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_emotion_examples(rows, cols, deterministic=False) :\n  cur_emot = 0\n  seed(None)\n  fig, axs = plot.subplots(rows, cols, figsize=(15,15))\n  #print first image on 8th cell, which is empty\n  #print_sub_image(x[0][0], title=\"\", subpl=axs[rows-1][cols-1])\n  fig.delaxes(axs[rows-1,cols-1])\n  #axs[rows-1,cols-1].set_axis_off()\n  while (cur_emot < len(emotions)) :\n    idx = int(random() * len_dataset) if not(deterministic) else (idx + 1)\n    if y[idx] == cur_emot :\n      plot.figure(cur_emot)\n      cur_row = cur_emot // cols\n      cur_col = cur_emot % cols\n      print_sub_image(x[idx][0], title=emotions[cur_emot], subpl=axs[cur_row][cur_col])\n      cur_emot += 1\n\nplot_emotion_examples(2, 4)","metadata":{"id":"bsV5Kh3SfdOI","execution":{"iopub.status.busy":"2021-12-22T15:57:18.221446Z","iopub.execute_input":"2021-12-22T15:57:18.221684Z","iopub.status.idle":"2021-12-22T15:57:19.090831Z","shell.execute_reply.started":"2021-12-22T15:57:18.221656Z","shell.execute_reply":"2021-12-22T15:57:19.090124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_filters_examples(rows, cols) :\n  seed(None)\n  idx = int(random() * len_dataset)\n  fig, axs = plot.subplots(rows, cols, figsize=(20,20))\n  for i in range(rows * cols) :\n      #set i as the index of the i-th figure\n      plot.figure(i)\n      #obtain row, col from i\n      cur_row = i // cols\n      cur_col = i % cols\n      #print image with the i-th filter\n      print_sub_image(x[idx][i], title=data.columns[2+i], subpl=axs[cur_row][cur_col])\n\nplot_filters_examples(2, 7)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:00:36.855078Z","iopub.execute_input":"2021-12-22T16:00:36.855390Z","iopub.status.idle":"2021-12-22T16:00:38.842642Z","shell.execute_reply.started":"2021-12-22T16:00:36.855341Z","shell.execute_reply":"2021-12-22T16:00:38.841234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split random by label (stratify=y)\nseed(None)\nsplit_seed = (int)(random() * 100)\n#split_seed = 99\nprint('split seed:', split_seed)\n\nX_train, X_valid_test, y_train, y_valid_test = train_test_split(\n      x, y, shuffle=True, stratify=y, test_size=0.3, random_state=split_seed)\n\nX_test, X_valid, y_test, y_valid = train_test_split(\n      X_valid_test, y_valid_test, shuffle=True, stratify=y_valid_test, test_size=0.5, random_state=split_seed)","metadata":{"id":"ku1rMblo8QkK","execution":{"iopub.status.busy":"2021-12-22T15:57:21.065050Z","iopub.execute_input":"2021-12-22T15:57:21.065459Z","iopub.status.idle":"2021-12-22T15:57:21.165612Z","shell.execute_reply.started":"2021-12-22T15:57:21.065422Z","shell.execute_reply":"2021-12-22T15:57:21.164106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del x\ndel y\ndel X_valid_test\ndel y_valid_test","metadata":{"execution":{"iopub.status.busy":"2021-12-22T15:57:21.166919Z","iopub.execute_input":"2021-12-22T15:57:21.167183Z","iopub.status.idle":"2021-12-22T15:57:21.171416Z","shell.execute_reply.started":"2021-12-22T15:57:21.167148Z","shell.execute_reply":"2021-12-22T15:57:21.170686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_valid_test_count_df = pd.DataFrame(y_valid_test, columns=['emotion']).value_counts().sort_index()\n\n#for row in y_valid_test_count_df.iteritems() :\n  #emot = (int)(row[0][0])\n  #count = row[1]\n  #print(emot, count)","metadata":{"id":"viPXZZGWOE1m","execution":{"iopub.status.busy":"2021-12-22T15:57:21.172955Z","iopub.execute_input":"2021-12-22T15:57:21.173462Z","iopub.status.idle":"2021-12-22T15:57:21.180294Z","shell.execute_reply.started":"2021-12-22T15:57:21.173427Z","shell.execute_reply":"2021-12-22T15:57:21.179686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.to(device)\nX_valid = X_valid.to(device)\nX_test  =  X_test.to(device)\n\ny_train = y_train.to(device, dtype=torch.long)\ny_valid = y_valid.to(device, dtype=torch.long)\ny_test  =  y_test.to(device, dtype=torch.long)\n\ntrain_dataset = TensorDataset(X_train, y_train)\nvalid_dataset = TensorDataset(X_valid, y_valid)\ntest_dataset  = TensorDataset(X_test,  y_test)\n\nbatch_size = 32\n\ntrainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\ntestloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=True)","metadata":{"id":"manS8b6hq6u8","execution":{"iopub.status.busy":"2021-12-22T15:57:21.181528Z","iopub.execute_input":"2021-12-22T15:57:21.182123Z","iopub.status.idle":"2021-12-22T15:57:21.192898Z","shell.execute_reply.started":"2021-12-22T15:57:21.182086Z","shell.execute_reply":"2021-12-22T15:57:21.192201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(trainloader.dataset))\nprint(len(validloader.dataset))\nprint(len(testloader.dataset))","metadata":{"id":"qXIY8Q9TDxYw","execution":{"iopub.status.busy":"2021-12-22T15:57:21.195452Z","iopub.execute_input":"2021-12-22T15:57:21.195637Z","iopub.status.idle":"2021-12-22T15:57:21.203430Z","shell.execute_reply.started":"2021-12-22T15:57:21.195614Z","shell.execute_reply":"2021-12-22T15:57:21.202474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DynamicNetInceptions(nn.Module):\n\n    def __init__(self, dropout_prob, conv__layer_repetitions=(1,1,1), conv__in_channels=1, conv__out_channels=(6,12,24), lin__out_dimension=(16*7*5,16,len(emotions)), incep__num_layers=4, incep__multiplier=2, im_h=im_h, im_l=im_l) :\n      super(DynamicNetInceptions, self).__init__()\n\n      # PARAMETERS SECTION\n      self.pool_size = (2,2)\n      self.kernel_size = (3,3)\n      self.padding = 1\n      self.num_of_conv_layers = len(conv__layer_repetitions) # default = 3\n      self.num_of_lin_layers = len(lin__out_dimension) # default = 3\n      self.dropout_prob = dropout_prob\n        \n      self.first_dropout = nn.Dropout2d(p=self.dropout_prob[0])\n      self.second_dropout = nn.Dropout2d(p=self.dropout_prob[1])\n        \n      self.skip = nn.Identity()\n      \n      in_chan = conv__in_channels\n      self.convs = []\n\n      if (len(conv__layer_repetitions) != len(conv__out_channels)) :\n        print(\"ERROR CHECK SIZES!!\")\n\n      # CONVOLUTIONAL SECTION\n      out_chan = 0\n      for big_layer in range(self.num_of_conv_layers) : # default = 3\n        out_chan = conv__out_channels[big_layer]\n        cur_rep_big_layer = conv__layer_repetitions[big_layer]\n        for repeat_layer in range(cur_rep_big_layer) : #a, b, c, ...\n          self.convs += [ nn.Conv2d(in_chan, out_chan, self.kernel_size, padding=self.padding) ]\n          #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n          self.convs += [ nn.ReLU() ]\n          in_chan = out_chan\n        self.convs += [ nn.MaxPool2d(self.pool_size) ]\n        #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n    \n      #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n\n      # INCEPTION SECTION\n      in_chan = out_chan\n      self.incep__multiplier = incep__multiplier\n      self.incep__num_layers = incep__num_layers\n      self.incep_first = self.inception_module(in_chan)\n      self.incep_after = []\n      total_out_chan = incep__multiplier*(64 + 128 + 32 + 32) #256 * out_multiplier\n      in_chan = total_out_chan\n      for inception_layer in range(incep__num_layers - 1) :\n          cur_incep = self.inception_module(in_chan)\n          self.incep_after += [ cur_incep ]\n        \n      #self.incep_after += [ nn.Dropout2d(p=self.dropout_prob) ]\n\n      #final output dimension\n      self.final_conv_dim = total_out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n\n      # LINEAR FC SECTION\n      in_dim = self.final_conv_dim\n\n      self.linear_fc = []\n      for lin_layer in range(self.num_of_lin_layers) :\n        out_dim = lin__out_dimension[lin_layer]\n        self.linear_fc += [ nn.Linear(in_dim, out_dim) ]\n        #self.linear_fc += [ nn.Dropout2d(p=self.dropout_prob) ]\n        self.linear_fc += [ nn.ReLU() ]\n        in_dim = out_dim\n      \n      # SEQUENTIAL SECTION\n      self.convs_seq = nn.Sequential(*self.convs).to(device)\n      self.linear_fc_seq = nn.Sequential(*self.linear_fc).to(device)\n      self.softmax = nn.Softmax(1).to(device)\n\n    def inception_module(self, in_chan, out_1x1=64, out_3x3=[96,128], out_5x5=[16,32], out_pool=32) :\n      \n      mul = self.incep__multiplier\n    \n      branch_1x1 = nn.Sequential(\n          nn.Conv2d(in_chan, out_1x1*mul, kernel_size=1) #conv 1x1\n      ).to(device)\n\n      branch_3x3 = nn.Sequential(\n        nn.Conv2d(in_chan,          (out_3x3[0])*mul, kernel_size=1),           # conv 1x1\n        nn.Conv2d((out_3x3[0])*mul, (out_3x3[1])*mul, kernel_size=3, padding=1) # conv 3x3\n      ).to(device)\n\n      branch_5x5 =  nn.Sequential(\n        nn.Conv2d(in_chan,          (out_5x5[0])*mul, kernel_size=1),           # conv 1x1\n        nn.Conv2d((out_5x5[0])*mul, (out_5x5[1])*mul, kernel_size=5, padding=2) # conv 5x5\n      ).to(device)\n\n      branch_pool =  nn.Sequential(\n        nn.MaxPool2d(kernel_size=3, stride=1, padding=0), # max_pool 3x3\n        nn.Conv2d(in_chan, out_pool*mul, kernel_size=1, stride=1, padding=1) # conv 1x1\n      ).to(device)\n        \n      return [ branch_1x1, branch_3x3, branch_5x5, branch_pool ]\n\n    def print_net(self) :\n        \n      print(\"__Convolutionals Start__\")\n      print(self.convs_seq)\n      print(\"__Convolutionals End__\")\n      print()\n      \n      print(self.first_dropout)\n      print()\n    \n      print(\"__Inception Start (with skip)__\")\n      print(\"Inception__1 with dim: N -> (256 * mul)\")\n      print(self.incep_first)\n      print(f\"Inception__2,...,{self.incep__num_layers} with dim: (256 * mul) -> (256 * mul)\")\n      print(self.incep_after[0])\n      print(\"__Inception End__\")\n      print()\n        \n      #if (self.incep__num_layers > 0) :\n      #    print(\"__Inception Start (with skip)__\")\n      #    print(\"Inception__0:\")\n      #    print(self.incep_first)\n      #    for i in range(self.incep__num_layers - 1) :\n      #        print(f\"Inception__{i+1}\")\n      #        print(self.incep_after[i])\n      #    print(\"__Inception End__\")\n      #print(f\"Channel concat: torch.cat(branches)\")\n    \n      print(self.second_dropout)\n      print()\n    \n      print(f\"Reshape(-1, {self.final_conv_dim})\")\n      print()\n    \n      print(\"__Linear Start__\")\n      print(self.linear_fc_seq)\n      print(\"__Linear End__\")\n      print()\n    \n      print(self.softmax)\n      print()\n\n    def run_inception(self, x, inception) :\n      x_1x1  = (inception[0])(x)\n      x_3x3  = (inception[1])(x)\n      x_5x5  = (inception[2])(x)\n      x_pool = (inception[3])(x)\n      concat = torch.cat((x_1x1, x_3x3, x_5x5, x_pool), 1)\n      return concat\n    \n    def forward(self, x):\n\n      #print(x.size())\n      x = self.convs_seq(x)\n    \n      x = self.second_dropout(x)\n        \n      #print(\"after convs\", x.size())\n      if (self.incep__num_layers > 0) :\n        x = self.run_inception(x, self.incep_first) \n        #print(\"after first\", x.size()) \n        for inception in self.incep_after : \n          x = self.run_inception(x, inception) + self.skip(x)\n          #print(\"after ith inception\",x.size())\n\n      x = self.first_dropout(x)\n    \n      x = x.reshape(-1, self.final_conv_dim)\n      #print(x.size())\n      \n      x = self.linear_fc_seq(x)\n      \n      x = self.softmax(x)\n\n      return x\n\n#net = DynamicNetInceptions(0.1,conv__layer_repetitions=(2,2,1), conv__in_channels=3)\n#net.print_net()","metadata":{"id":"BkJpt-vvdr1M","execution":{"iopub.status.busy":"2021-12-22T15:57:21.205433Z","iopub.execute_input":"2021-12-22T15:57:21.206003Z","iopub.status.idle":"2021-12-22T15:57:21.234729Z","shell.execute_reply.started":"2021-12-22T15:57:21.205968Z","shell.execute_reply":"2021-12-22T15:57:21.233831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DynamicNetBasic(nn.Module):\n\n    def __init__(self, dropout_prob, conv__layer_repetitions=(1,1,1), conv__in_channels=1, conv__out_channels=(6,12,24), lin__out_dimension=(16*7*5,16,len(emotions)), im_h=im_h, im_l=im_l) :\n      super(DynamicNetBasic, self).__init__()\n\n      #params\n      self.pool_size = (2,2)\n      self.kernel_size = (3,3)\n      self.padding = 1\n      self.num_of_conv_layers = len(conv__layer_repetitions) # default = 3\n      self.num_of_lin_layers = len(lin__out_dimension) # default = 3\n      self.dropout_prob = dropout_prob\n      \n      in_chan = conv__in_channels\n      self.convs = [] \n\n      if (len(conv__layer_repetitions) != len(conv__out_channels)) :\n        print(\"ERROR\")\n\n      for big_layer in range(self.num_of_conv_layers) : # default = 3\n        out_chan = conv__out_channels[big_layer]\n        cur_rep_big_layer = conv__layer_repetitions[big_layer]\n        for repeat_layer in range(cur_rep_big_layer) : #a, b, c, ...\n          self.convs += [ nn.Conv2d(in_chan, out_chan, self.kernel_size, padding=self.padding) ]\n          #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n          self.convs += [ nn.ReLU() ]\n          in_chan = out_chan\n        self.convs += [nn.MaxPool2d(self.pool_size)]\n\n      self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n      \n      #final output dimension\n      self.final_conv_dim = out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n\n      # linears\n      in_dim = self.final_conv_dim\n\n      self.linear_fc = []\n      for lin_layer in range(self.num_of_lin_layers) :\n        out_dim = lin__out_dimension[lin_layer]\n        self.linear_fc += [ nn.Linear(in_dim, out_dim) ]\n        #self.linear_fc += [ nn.Dropout2d(p=self.dropout_prob) ]\n        self.linear_fc += [ nn.ReLU() ]\n        in_dim = out_dim\n      \n      self.softmax = nn.Softmax(1)\n\n      self.features = nn.Sequential(*self.convs).to(device)\n      self.linear_fc = nn.Sequential(*self.linear_fc).to(device)\n\n      #print(self.features)\n      #print(self.linear_fc)\n\n    def print_net(self) :\n      print(self.features)\n      print(f\"Reshape(-1, {self.final_conv_dim})\")\n      print(self.linear_fc)\n      print(self.softmax)\n\n    def forward(self, x):\n      \n      x = self.features(x)\n      x = x.reshape(-1, self.final_conv_dim)\n      x = self.linear_fc(x)\n      \n      x = self.softmax(x)\n\n      return x\n\n#net = DynamicNetBasic(0.1,conv__layer_repetitions=(2,2,1), conv__in_channels=3)\n#net.print_net()","metadata":{"id":"jbroYNSnQqYU","execution":{"iopub.status.busy":"2021-12-22T15:57:21.240805Z","iopub.execute_input":"2021-12-22T15:57:21.241227Z","iopub.status.idle":"2021-12-22T15:57:21.257146Z","shell.execute_reply.started":"2021-12-22T15:57:21.241195Z","shell.execute_reply":"2021-12-22T15:57:21.255522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Optimization:\n    def __init__(self, model, loss_fn, optimizer, schedulers=[]):\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.schedulers = schedulers\n        self.train_losses = []\n        self.val_losses = []\n        self.train_accuracies = []\n        self.val_accuracies = []\n    \n    def count_preds_correct(self, y_pred, y) :\n      preds = torch.argmax(y_pred, axis=1)\n      count = preds.eq(y.data.view_as(preds)).cpu().sum()\n      #print(count, preds.size(), y.size())\n      #for i in range(preds.size()[0]) :\n      #      print(preds[i], y[i], preds[i].eq(y[i].data.view_as(preds[i])).cpu())\n      #print(\"end\")\n      return count\n    \n    def train_step(self, x, y):\n        #count correct predictions\n        preds_correct = 0\n        # Set training mode\n        self.model.train()\n        # Predict\n        y_pred = self.model(x)\n        # Computes loss, gradients\n        #print(y.size(), y_pred.size())\n        loss = self.loss_fn(y_pred, y)\n        loss.backward()\n        # Updates parameters, set to zero gradients\n        self.optimizer.step()\n        self.optimizer.zero_grad()\n        # Return loss, num of correct predictions\n        x = self.count_preds_correct(y_pred, y)\n        preds_correct += x\n        return loss.item(), preds_correct\n    \n    def train(self, train_loader, val_loader, batch_size=32, n_epochs=50, n_features=n_features, im_h=im_h, im_l=im_l):\n        for epoch in range(n_epochs + 1):\n            #print(f\"epoch: {epoch}\")\n            batch_train_losses = []\n            batch_train_accs = []\n            train_i = 0\n            val_i = 0\n            train_correct = 0\n            val_correct = 0\n            \n            #for x in train_loader.dataset.tensors :\n              #print(type(x), x.get_device()) # CUDA -> 0, CPU -> -1\n\n            #print(\"training\")\n            for idx, batch in enumerate(train_loader):\n                x_batch, y_batch = batch        \n                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n\n                #now = datetime.now().strftime(\"%H:%M:%S\")\n                #print(f\"{now} epoch: {epoch}, train_i: {train_i}, val_i: {val_i}\")\n                #x_batch = x_batch.view([cur_batch_size, -1, n_features]).to(device)\n                cur_batch_size = len(x_batch)\n                x_batch = x_batch.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n                y_batch = y_batch.to(device)\n                #print(x_batch.get_device(), y_batch.get_device())\n                #print(f\"x_batch.size: {x_batch.size()}, y_val: {y_batch.size()}\")\n                #cur_train_correct = 0\n                loss, train_correct = self.train_step(x_batch, y_batch)\n                batch_train_accs.append(train_correct / cur_batch_size)\n                batch_train_losses.append(loss)\n                train_i = train_i + 1\n            train_acc = np.mean(batch_train_accs)\n            train_loss = np.mean(batch_train_losses)\n            self.train_accuracies.append(train_acc)\n            self.train_losses.append(train_loss)\n            for cur_scheduler in self.schedulers :\n              cur_scheduler.step()\n  \n            #print(\"validation\")\n            with torch.no_grad():\n                batch_val_losses = []\n                batch_val_accs = []\n                for x_val, y_val in val_loader:\n                    #now = datetime.now().strftime(\"%H:%M:%S\")\n                    #print(f\"{now} epoch: {epoch}, train_i: {train_i}, val_i: {val_i}\")\n                    cur_batch_size = len(x_val)\n                    #print(f\"len(x_val): {cur_batch_size}\")\n                    #x_val = x_val.view([cur_batch_size, -1, n_features]).to(device)\n                    x_val = x_val.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n                    y_val = y_val.to(device)\n                    #print(f\"x_val.size: {x_val.size()}, y_val: {y_val.size()}\")\n                    self.model.eval()\n                    y_pred = self.model(x_val)\n                    val_correct = self.count_preds_correct(y_pred, y_val)\n                    val_loss = self.loss_fn(y_pred, y_val).item()\n                    batch_val_acc_cur = (val_correct / cur_batch_size)\n                    #print(val_correct, cur_batch_size, batch_val_acc_cur)\n                    batch_val_accs.append(batch_val_acc_cur)\n                    batch_val_losses.append(val_loss)\n                    val_i = val_i + 1\n                val_acc = np.mean(batch_val_accs)\n                val_loss = np.mean(batch_val_losses)\n                self.val_accuracies.append(val_acc)\n                self.val_losses.append(val_loss)\n\n            if (epoch % 1 == 0):\n                now = datetime.now().strftime(\"%H:%M:%S\")\n                print(f\"{now} [{epoch:2d}/{n_epochs}] Train: [ loss: {train_loss:.8f}, acc: {train_acc:.8f} ] \\t Validation: [ loss: {val_loss:.8f}, acc: {val_acc:.8f} ]\")\n\n        return self.model.state_dict()\n\n    def evaluate(self, test_loader, batch_size=1, n_features=1, im_h=48, im_l=48):\n        #print(\"testing\")\n        with torch.no_grad():\n            predictions = []\n            real_values = []\n            for x_test, y_test in test_loader:\n                cur_batch_size = len(x_test)\n                #x_test = x_test.view([cur_batch_size, -1, n_features]).to(device)\n                x_test = x_test.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n                y_test = y_test.to(device)\n                self.model.eval()\n                y_pred = self.model(x_test)\n                predictions.append(y_pred.to('cpu').detach().numpy())\n                real_values.append(y_test.to('cpu').detach().numpy())\n\n        return predictions, real_values      \n\n    def plot_losses(self):\n        plot.plot(self.train_losses, label=\"Training loss\")\n        plot.plot(self.val_losses, label=\"Validation loss\")\n        plot.legend()\n        plot.title(\"Evolution of losses over time\")\n        plot.xlabel(\"Epochs\")\n        plot.ylabel(\"Losses\")\n        plot.show()\n        plot.close()\n\n    def plot_accuracies(self):\n        plot.plot(self.train_accuracies, label=\"Training accuracy\")\n        plot.plot(self.val_accuracies, label=\"Validation accuracy\")\n        plot.legend()\n        plot.title(\"Evolution of accuracies over time\")\n        plot.xlabel(\"Epochs\")\n        plot.ylabel(\"Accuracies\")\n        plot.show()\n        plot.close()\n  \n    def plot_losses_accuracies(self, figsize=(12,4)):\n        fig, axs = plot.subplots(1, 2, figsize=figsize)\n        #losses\n        plot_1 = axs[0]\n        plot_1.plot(self.train_losses, label=\"Training loss\")\n        plot_1.plot(self.val_losses, label=\"Validation loss\")\n        plot_1.legend()\n        plot_1.set_title(\"Evolution of losses over time\")\n        plot_1.set_xlabel(\"Epochs\")\n        plot_1.set_ylabel(\"Losses\")\n        #accuracies\n        plot_2 = axs[1]\n        plot_2.plot(self.train_accuracies, label=\"Training accuracy\")\n        plot_2.plot(self.val_accuracies, label=\"Validation accuracy\")\n        plot_2.legend()\n        plot_2.set_title(\"Evolution of accuracies over time\")\n        plot_2.set_xlabel(\"Epochs\")\n        plot_2.set_ylabel(\"Accuracies\")\n        ","metadata":{"id":"mHdagsNmyFKL","execution":{"iopub.status.busy":"2021-12-22T15:57:21.259378Z","iopub.execute_input":"2021-12-22T15:57:21.259935Z","iopub.status.idle":"2021-12-22T15:57:21.289944Z","shell.execute_reply.started":"2021-12-22T15:57:21.259883Z","shell.execute_reply":"2021-12-22T15:57:21.289104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#R1 NO INCEPTION:\n#n_epochs = 40\n#learning_rate = 5e-5\n#weight_decay = 1e-9\n#dropout_prob = 0.35\n\n#dynamic net parameters\n#conv part:\n#conv__in_channels=n_features\n#conv__out_channels=(288,566,1122,2244)\n#conv__layer_repetitions=(4,3,2,1) #a=3, b=2, c=1\n#linear part:\n#lin__out_dimension=(1024,356,158,64,len(emotions))","metadata":{"id":"NgcrNXxDorAR","execution":{"iopub.status.busy":"2021-12-22T15:57:21.292189Z","iopub.execute_input":"2021-12-22T15:57:21.292616Z","iopub.status.idle":"2021-12-22T15:57:21.301831Z","shell.execute_reply.started":"2021-12-22T15:57:21.292580Z","shell.execute_reply":"2021-12-22T15:57:21.301070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#R2 YES INCEPTION:\n#n_epochs = 30\n#learning_rate = 1e-4\n#weight_decay = 1e-8\n#dropout_prob = 0.62\n\n#dynamic net parameters\n#conv part:\n#conv__in_channels=n_features     #num_of_channels in dataset = 3: original, \n#conv__out_channels=     (200,400,600,800) #out channels of each conv\n#conv__layer_repetitions=(  2,  2,  2,  1) #number of repetitions of i-th conv before go to next one, first has channels (N-1 -> N), others (N -> N)\n#linear part:\n#lin__out_dimension=(432, 108, 27, len(emotions)) #out dimension of fc, last one = 7\n#inception part:\n#incep__num_layers=30 #num of inspection modules, NB the first has shape (N -> 256*mul), others (256*mul -> 256*mul)\n#incep__multiplier=3  #multiplier of the default out dim of resnet: (64 for 1x1, 128 per 3x3, 32 per 5x5, 32 per maxpool)\n#NB: reshape = 256 * incep__multiplier * ((48 // (2 ** num_of_conv_layers)) ** 2) = 6912 (if mul=3, layers=4)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T16:02:31.428225Z","iopub.execute_input":"2021-12-22T16:02:31.428838Z","iopub.status.idle":"2021-12-22T16:02:31.432894Z","shell.execute_reply.started":"2021-12-22T16:02:31.428799Z","shell.execute_reply":"2021-12-22T16:02:31.432022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 30\nlearning_rate = 1e-4\nweight_decay = 1e-8\n#if dropout before and after inception: 25% < dropout < 30%\n#if dropout       only after inception: 60% < dropout > 70%\ndropout_prob = ( 0.25, 0.5 )\n\n#dynamic net parameters\n#conv part:\nconv__in_channels = n_features\nconv__out_channels =      (288,566,1122,2244)\nconv__layer_repetitions = (  2,  2,   1,   1)\n#linear part:\nlin__out_dimension = (432, 108, 27, len(emotions))\n#inception part:\nincep__num_layers = 35 #num of inspection modules, NB the first has shape (N -> 256*mul), others (256*mul -> 256*mul)\nincep__multiplier =  3 #multiplier of the default out dim of resnet: (64 for 1x1, 128 per 3x3, 32 per 5x5, 32 per maxpool)\n#NB: reshape = 256 * incep__multiplier * ((48 // (2 ** num_of_conv_layers)) ** 2) = 6912 (if mul=3, layers=4)\n\nmodel = DynamicNetInceptions(dropout_prob, conv__layer_repetitions, conv__in_channels, conv__out_channels, lin__out_dimension, incep__num_layers, incep__multiplier)\n#model = DynamicNetBasic(dropout_prob, conv__layer_repetitions, conv__in_channels, conv__out_channels, lin__out_dimension)\nnext(model.parameters()).device\nmodel.print_net()\n\nloss_fn = torch.nn.CrossEntropyLoss(reduction='sum') \n#loss_fn = torch.nn.KLDivLoss(reduction='sum') \n#loss_fn = torch.nn.NLLLoss(reduction='sum')\n\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n#optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n\nschedulers = [ \n    lr_scheduler.ExponentialLR(optimizer, gamma=0.9),\n    lr_scheduler.MultiStepLR(optimizer, milestones=[i for i in range(5, n_epochs, 5)], gamma=0.85),\n]\n\n#train\nopt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer, schedulers=schedulers)\nmodel_state_dict = opt.train(trainloader, validloader, batch_size=batch_size, n_epochs=n_epochs, n_features=n_features)\nopt.plot_losses_accuracies() \n#test\ny_pred_numpy, y_test_numpy = opt.evaluate(testloader, batch_size=1, n_features=n_features)","metadata":{"id":"pF8gbnsVybcB","execution":{"iopub.status.busy":"2021-12-22T16:02:31.439510Z","iopub.execute_input":"2021-12-22T16:02:31.440003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flat_list(main_list):\n    return [item for sub_list in main_list for item in sub_list]\n\n#remove batch divisions, get only predn_featuress\ny_pred_list = [ np.argmax(item) for item in flat_list(y_pred_numpy)]\ny_test_list = flat_list(y_test_numpy)\n\nnum_of_emotions = len(emotions)\ntrue_preds  = [ 0 for _ in range(num_of_emotions) ]\nfalse_preds = [ 0 for _ in range(num_of_emotions) ]\n\nfor i in range(len(y_test_list)) :\n  emot_pred = y_pred_list[i]\n  emot_real = y_test_list[i]\n  if emot_pred == emot_real :\n    true_preds[emot_real] += 1\n  else :\n    false_preds[emot_real] += 1\n\naccuracy = [ (true_preds[i] / (true_preds[i] + false_preds[i])) for i in range(num_of_emotions) ]\ntotal_approx_acc = np.mean(accuracy)\ntotal_true = np.sum(true_preds)\ntotal_false = np.sum(false_preds)\ntotal_real_acc = total_true / (total_true + total_false)\n\nanalysis_df = pd.DataFrame(\n    list(zip(list(emotions), true_preds, false_preds, accuracy)), \n    columns=['emotions', 'true_preds', 'false_preds', 'accuracy']\n)\nprint(f\"{total_approx_acc:.5f} mean of accuracy of each label\")\nprint(f\"{total_real_acc:.5f} accuracy of all test set\")\nprint(analysis_df)","metadata":{"id":"GWB9LNDsVYYs","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# store y_pred, y_real to df\ny_pred_real_df = pd.DataFrame(\n    list(zip(y_pred_list, y_test_list)), \n    columns=['y_pred_list', 'y_test_list']\n)\nprint(y_pred_real_df)","metadata":{"id":"sl4FmZPuG1dG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# store parameters to df\nparams_dict = {\n    'n_epochs':                 [n_epochs],\n    'learning_rate':            [learning_rate],\n    'weight_decay':             [weight_decay],\n    'dropout_prob':             [dropout_prob],\n    'conv__in_channels':        [conv__in_channels],\n    'conv__out_channels':       [conv__out_channels],\n    'conv__layer_repetitions':  [conv__layer_repetitions],\n    'lin__out_dimension':       [lin__out_dimension],\n    'loss_fn':                  [loss_fn],\n    'optimizer':                [optimizer.__class__.__name__],\n    'split_seed':               [split_seed],\n    'incep__num_layers':        [incep__num_layers],\n    'incep__multiplier':        [incep__multiplier]\n}\n\nparams_df = pd.DataFrame(params_dict)\nprint(params_df.T)","metadata":{"id":"G8L65IdIZj3d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# store losses and accuracies to df\nlosses_accuracies_df = pd.DataFrame(\n    list(zip(opt.train_losses, opt.val_losses, opt.train_accuracies, opt.val_accuracies)),\n    columns=['train_losses', 'val_losses', 'train_accuracies', 'val_accuracies']\n)\nprint(losses_accuracies_df)","metadata":{"id":"TE8sq69NkEj0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scikitplot\nscikitplot.metrics.plot_confusion_matrix(y_pred_list, y_test_list, figsize=(7,7))\nplot.savefig(\"confusion_matrix.png\")","metadata":{"id":"cOCXANlHG1dG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\nimport base64\n\ndef create_download_link(df, filename, title = \"Download CSV file\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#export parameters, analysis to csv file\nnow = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\nextension = '.csv'\n\nto_export = {\n    \"_y_pred_real_\":       y_pred_real_df,\n    \"_params_\" :           params_df,\n    \"_analysis_\":          analysis_df,\n    \"_losses_accuracies_\": losses_accuracies_df\n}\n\nfor name_cur, df_cur in to_export.items() :\n    filename = (export_dir + now + name_cur + extension)\n    df_cur.to_csv(filename, sep=';')\n    print(f\"link of {name_cur}:\")\n    create_download_link(df_cur, filename)\n    ","metadata":{"id":"nKnQ5ZnIevrG","trusted":true},"execution_count":null,"outputs":[]}]}