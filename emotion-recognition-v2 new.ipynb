{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:00.786348Z","iopub.status.busy":"2021-12-22T15:40:00.786011Z","iopub.status.idle":"2021-12-22T15:40:03.149954Z","shell.execute_reply":"2021-12-22T15:40:03.149257Z","shell.execute_reply.started":"2021-12-22T15:40:00.786236Z"},"id":"GfUyuvT6ddv_","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import math\n","from random import seed\n","from random import random\n","import seaborn as sea\n","import matplotlib.pyplot as plot\n","import torch\n","from torch.utils.data import TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from tqdm.auto import tqdm\n","from datetime import datetime"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:03.152006Z","iopub.status.busy":"2021-12-22T15:40:03.151748Z","iopub.status.idle":"2021-12-22T15:40:03.155826Z","shell.execute_reply":"2021-12-22T15:40:03.155118Z","shell.execute_reply.started":"2021-12-22T15:40:03.151972Z"},"trusted":true},"outputs":[],"source":["dataset_filename = 'fer2013_augmented_v3.csv'\n","#image sizes\n","im_l = 48\n","im_h = 48"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:03.157760Z","iopub.status.busy":"2021-12-22T15:40:03.157222Z","iopub.status.idle":"2021-12-22T15:40:03.165953Z","shell.execute_reply":"2021-12-22T15:40:03.165311Z","shell.execute_reply.started":"2021-12-22T15:40:03.157719Z"},"trusted":true},"outputs":[],"source":["#can_be_computed = [ 'local', 'colab', 'kaggle' ]\n","actually_computed = 'kaggle'"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:03.169856Z","iopub.status.busy":"2021-12-22T15:40:03.169423Z","iopub.status.idle":"2021-12-22T15:40:03.175592Z","shell.execute_reply":"2021-12-22T15:40:03.174856Z","shell.execute_reply.started":"2021-12-22T15:40:03.169808Z"},"trusted":true},"outputs":[],"source":["# for local\n","# --------------------------------------------\n","if (actually_computed == 'local') :\n","    import_dir = ''\n","    export_dir = 'output_csv/'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:03.177513Z","iopub.status.busy":"2021-12-22T15:40:03.177147Z","iopub.status.idle":"2021-12-22T15:40:03.185104Z","shell.execute_reply":"2021-12-22T15:40:03.184388Z","shell.execute_reply.started":"2021-12-22T15:40:03.177478Z"},"id":"WyotH4_nfKZN","trusted":true},"outputs":[],"source":["# for google colab \n","# --------------------------------------------\n","if (actually_computed == 'colab') :\n","    import_dir = '/content/drive/MyDrive/Colab Notebooks/DL/progetto/'\n","    export_dir = import_dir + 'output_csv/'\n","\n","    # Mount data from drive\n","    from google.colab import drive\n","    drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:03.186673Z","iopub.status.busy":"2021-12-22T15:40:03.186053Z","iopub.status.idle":"2021-12-22T15:40:03.195737Z","shell.execute_reply":"2021-12-22T15:40:03.194935Z","shell.execute_reply.started":"2021-12-22T15:40:03.186637Z"},"id":"Cr3L0treiydL","trusted":true},"outputs":[],"source":["# for kaggle\n","# --------------------------------------------\n","if (actually_computed == 'kaggle') :\n","    import_dir = '/kaggle/input/fer2013-v3/'\n","    export_dir = '/kaggle/working/output_csv/'\n","\n","    if(not os.path.exists(export_dir)) :\n","        os.makedirs(export_dir)\n","    print(os.path.exists(export_dir))"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:40:03.197816Z","iopub.status.busy":"2021-12-22T15:40:03.197242Z","iopub.status.idle":"2021-12-22T15:41:10.638182Z","shell.execute_reply":"2021-12-22T15:41:10.637426Z","shell.execute_reply.started":"2021-12-22T15:40:03.197778Z"},"trusted":true},"outputs":[],"source":["dataset_filepath = import_dir + dataset_filename\n","print(f\"reading dataset: {dataset_filepath}\")\n","data = pd.read_csv(dataset_filepath)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:10.641425Z","iopub.status.busy":"2021-12-22T15:41:10.639357Z","iopub.status.idle":"2021-12-22T15:41:10.647191Z","shell.execute_reply":"2021-12-22T15:41:10.646541Z","shell.execute_reply.started":"2021-12-22T15:41:10.641394Z"},"trusted":true},"outputs":[],"source":["drop_columns = ['emotion', 'Usage' ] #, 'rotate_-60_degrees', 'rotate_+60_degrees']\n","used_columns = set(data.columns) - set(drop_columns)\n","print(used_columns)\n","im_d = n_features = len(used_columns)\n","print(im_d)\n","len_dataset = len(data)\n","print(len_dataset)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:10.648805Z","iopub.status.busy":"2021-12-22T15:41:10.648423Z","iopub.status.idle":"2021-12-22T15:41:10.667532Z","shell.execute_reply":"2021-12-22T15:41:10.666849Z","shell.execute_reply.started":"2021-12-22T15:41:10.648770Z"},"id":"WT49RKuk4Fnf","trusted":true},"outputs":[],"source":["#print the TRANSPOSE of a random row\n","seed(None)\n","img_idx = int(random() * len_dataset)\n","print('img_idx:', img_idx)\n","#random row in dataset:\n","print(data[img_idx:img_idx+1].T)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:10.670819Z","iopub.status.busy":"2021-12-22T15:41:10.670607Z","iopub.status.idle":"2021-12-22T15:41:10.688158Z","shell.execute_reply":"2021-12-22T15:41:10.687205Z","shell.execute_reply.started":"2021-12-22T15:41:10.670795Z"},"id":"P14R062hBzsy","trusted":true},"outputs":[],"source":["print(data[\"Usage\"].value_counts())"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:10.689814Z","iopub.status.busy":"2021-12-22T15:41:10.689560Z","iopub.status.idle":"2021-12-22T15:41:10.931232Z","shell.execute_reply":"2021-12-22T15:41:10.930483Z","shell.execute_reply.started":"2021-12-22T15:41:10.689780Z"},"id":"UuTQvRspeAez","trusted":true},"outputs":[],"source":["#emotions definition and plotting\n","\n","#emozioni = ('rabbia', 'disgusto', 'paura', 'felicit√†',  'tristezza', 'sorpresa', 'neutrale')\n","emotions =  ('rage',   'disgust',  'fear',  'happiness', 'sadness',   'surprise', 'neutral')\n","y = data['emotion']\n","\n","sx = sea.countplot(x=y)\n","plot.xticks(range(len(emotions)), emotions)\n","plot.xlabel(\"Emotions\")\n","plot.ylabel(\"Count\")\n","\n","num_of_emotions = data['emotion'].value_counts().sort_index()\n","print(num_of_emotions)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:10.933500Z","iopub.status.busy":"2021-12-22T15:41:10.933065Z","iopub.status.idle":"2021-12-22T15:41:10.985760Z","shell.execute_reply":"2021-12-22T15:41:10.984900Z","shell.execute_reply.started":"2021-12-22T15:41:10.933463Z"},"trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else :\n","    device = torch.device('cpu')\n","#device = torch.device('cpu')\n","print(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:10.990192Z","iopub.status.busy":"2021-12-22T15:41:10.989393Z","iopub.status.idle":"2021-12-22T15:41:10.997103Z","shell.execute_reply":"2021-12-22T15:41:10.996264Z","shell.execute_reply.started":"2021-12-22T15:41:10.990147Z"},"trusted":true},"outputs":[],"source":["def data_to_tensors_of_nparray(df, im_d=im_d, im_h=im_h, im_l=im_l):\n","    tensor_dataset = []\n","    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n","        image = []\n","        for im in row :\n","            image.append(np.array(im.split()))\n","        tensor_dataset.append(torch.Tensor(np.array(image).reshape(im_d, im_h, im_l).astype('double') / 255))\n","    return tensor_dataset\n","\n","#imgsList = data_to_tensors_of_nparray(data.drop(columns=drop_columns))"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:11.000575Z","iopub.status.busy":"2021-12-22T15:41:11.000346Z","iopub.status.idle":"2021-12-22T15:41:11.006581Z","shell.execute_reply":"2021-12-22T15:41:11.005744Z","shell.execute_reply.started":"2021-12-22T15:41:11.000548Z"},"trusted":true},"outputs":[],"source":["# for testing\n","#len_dataset = 1000\n","#x = torch.cat((data_to_tensors_of_nparray(data.drop(columns=drop_columns)[:len_dataset])),0).view(len_dataset,im_d,im_h,im_l).to(device)\n","#y = torch.Tensor(y)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:41:11.008816Z","iopub.status.busy":"2021-12-22T15:41:11.008073Z","iopub.status.idle":"2021-12-22T15:57:18.143062Z","shell.execute_reply":"2021-12-22T15:57:18.142327Z","shell.execute_reply.started":"2021-12-22T15:41:11.008785Z"},"trusted":true},"outputs":[],"source":["#on kaggle with GPU enabled: it will take about 15 minutes (14 GB CPU RAM, 16 GB GPU RAM)\n","#splitted in two parts to not exceed memory\n","\n","#x = torch.cat((data_to_tensors_of_nparray(data.drop(columns=drop_columns))),0).view(len_dataset,im_d,im_h,im_l).to(device)\n","\n","half = len_dataset // 2\n","\n","print(\"first half (1/2):\")\n","cur_df = data.drop(columns=drop_columns)[:half]\n","first_half = torch.cat(data_to_tensors_of_nparray(cur_df),0).view(half,im_d,im_h,im_l).to(device)\n","\n","print(\"second half (2/2):\")\n","cur_df = data.drop(columns=drop_columns)[half:]\n","second_half = torch.cat(data_to_tensors_of_nparray(cur_df),0).view(len_dataset-half,im_d,im_h,im_l).to(device)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:18.144814Z","iopub.status.busy":"2021-12-22T15:57:18.144547Z","iopub.status.idle":"2021-12-22T15:57:18.169418Z","shell.execute_reply":"2021-12-22T15:57:18.168680Z","shell.execute_reply.started":"2021-12-22T15:57:18.144778Z"},"trusted":true},"outputs":[],"source":["print(\"merging two halfs:\")\n","x = torch.cat((first_half, second_half), dim=0).view(len_dataset,im_d,im_h,im_l).to(device)\n","print(\"putting y in a Tensor\")\n","#do NOT put y to cuda before do train_test_split!\n","y = torch.Tensor(y)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:18.171479Z","iopub.status.busy":"2021-12-22T15:57:18.170962Z","iopub.status.idle":"2021-12-22T15:57:18.178897Z","shell.execute_reply":"2021-12-22T15:57:18.177991Z","shell.execute_reply.started":"2021-12-22T15:57:18.171440Z"},"trusted":true},"outputs":[],"source":["#get_device(): { 0 <==> 'cuda', -1 <==> 'cpu'}\n","print(type(x), x.get_device(), x.size())\n","print(type(y), y.get_device(), y.size())"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:18.181960Z","iopub.status.busy":"2021-12-22T15:57:18.181173Z","iopub.status.idle":"2021-12-22T15:57:18.205885Z","shell.execute_reply":"2021-12-22T15:57:18.204932Z","shell.execute_reply.started":"2021-12-22T15:57:18.181931Z"},"trusted":true},"outputs":[],"source":["#no more useful, save memory !!\n","del cur_df\n","del first_half\n","del second_half\n","#del data"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:18.210373Z","iopub.status.busy":"2021-12-22T15:57:18.209896Z","iopub.status.idle":"2021-12-22T15:57:18.219700Z","shell.execute_reply":"2021-12-22T15:57:18.218767Z","shell.execute_reply.started":"2021-12-22T15:57:18.210342Z"},"trusted":true},"outputs":[],"source":["def convert_image_tensor_to_np(tensor_image, im_l=im_l, im_h=im_h) :\n","    return 255 * tensor_image.detach().cpu().numpy().reshape((im_l,im_h))\n","\n","def print_image(tensor_image, title, im_l=im_l, im_h=im_h):\n","    np_image = convert_image_tensor_to_np(tensor_image)\n","    plot.imshow(np_image, cmap = 'gray')\n","    plot.title(str(title))\n","        \n","def print_sub_image(tensor_image, title, subpl, im_l=im_l, im_h=im_h):\n","    np_image = convert_image_tensor_to_np(tensor_image)\n","    subpl.imshow(np_image, cmap = 'gray')\n","    subpl.set_title(str(title))"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:18.221684Z","iopub.status.busy":"2021-12-22T15:57:18.221446Z","iopub.status.idle":"2021-12-22T15:57:19.090831Z","shell.execute_reply":"2021-12-22T15:57:19.090124Z","shell.execute_reply.started":"2021-12-22T15:57:18.221656Z"},"id":"bsV5Kh3SfdOI","trusted":true},"outputs":[],"source":["def plot_emotion_examples(rows, cols, deterministic=False) :\n","  cur_emot = 0\n","  seed(None)\n","  fig, axs = plot.subplots(rows, cols, figsize=(15,15))\n","  #print first image on 8th cell, which is empty\n","  #print_sub_image(x[0][0], title=\"\", subpl=axs[rows-1][cols-1])\n","  fig.delaxes(axs[rows-1,cols-1])\n","  #axs[rows-1,cols-1].set_axis_off()\n","  while (cur_emot < len(emotions)) :\n","    idx = int(random() * len_dataset) if not(deterministic) else (idx + 1)\n","    if y[idx] == cur_emot :\n","      plot.figure(cur_emot)\n","      cur_row = cur_emot // cols\n","      cur_col = cur_emot % cols\n","      print_sub_image(x[idx][0], title=emotions[cur_emot], subpl=axs[cur_row][cur_col])\n","      cur_emot += 1\n","\n","plot_emotion_examples(2, 4)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T16:00:36.855390Z","iopub.status.busy":"2021-12-22T16:00:36.855078Z","iopub.status.idle":"2021-12-22T16:00:38.842642Z","shell.execute_reply":"2021-12-22T16:00:38.841234Z","shell.execute_reply.started":"2021-12-22T16:00:36.855341Z"},"trusted":true},"outputs":[],"source":["def plot_filters_examples(rows, cols) :\n","  seed(None)\n","  idx = int(random() * len_dataset)\n","  fig, axs = plot.subplots(rows, cols, figsize=(20,20))\n","  for i in range(rows * cols) :\n","      #set i as the index of the i-th figure\n","      plot.figure(i)\n","      #obtain row, col from i\n","      cur_row = i // cols\n","      cur_col = i % cols\n","      #print image with the i-th filter\n","      print_sub_image(x[idx][i], title=data.columns[2+i], subpl=axs[cur_row][cur_col])\n","\n","plot_filters_examples(2, 7)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.065459Z","iopub.status.busy":"2021-12-22T15:57:21.065050Z","iopub.status.idle":"2021-12-22T15:57:21.165612Z","shell.execute_reply":"2021-12-22T15:57:21.164106Z","shell.execute_reply.started":"2021-12-22T15:57:21.065422Z"},"id":"ku1rMblo8QkK","trusted":true},"outputs":[],"source":["#split random by label (stratify=y)\n","seed(None)\n","split_seed = (int)(random() * 100)\n","#split_seed = 99\n","print('split seed:', split_seed)\n","\n","X_train, X_valid_test, y_train, y_valid_test = train_test_split(\n","      x, y, shuffle=True, stratify=y, test_size=0.3, random_state=split_seed)\n","\n","X_test, X_valid, y_test, y_valid = train_test_split(\n","      X_valid_test, y_valid_test, shuffle=True, stratify=y_valid_test, test_size=0.5, random_state=split_seed)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.167183Z","iopub.status.busy":"2021-12-22T15:57:21.166919Z","iopub.status.idle":"2021-12-22T15:57:21.171416Z","shell.execute_reply":"2021-12-22T15:57:21.170686Z","shell.execute_reply.started":"2021-12-22T15:57:21.167148Z"},"trusted":true},"outputs":[],"source":["del x\n","del y\n","del X_valid_test\n","del y_valid_test"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.173462Z","iopub.status.busy":"2021-12-22T15:57:21.172955Z","iopub.status.idle":"2021-12-22T15:57:21.180294Z","shell.execute_reply":"2021-12-22T15:57:21.179686Z","shell.execute_reply.started":"2021-12-22T15:57:21.173427Z"},"id":"viPXZZGWOE1m","trusted":true},"outputs":[],"source":["#y_valid_test_count_df = pd.DataFrame(y_valid_test, columns=['emotion']).value_counts().sort_index()\n","\n","#for row in y_valid_test_count_df.iteritems() :\n","  #emot = (int)(row[0][0])\n","  #count = row[1]\n","  #print(emot, count)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.182123Z","iopub.status.busy":"2021-12-22T15:57:21.181528Z","iopub.status.idle":"2021-12-22T15:57:21.192898Z","shell.execute_reply":"2021-12-22T15:57:21.192201Z","shell.execute_reply.started":"2021-12-22T15:57:21.182086Z"},"id":"manS8b6hq6u8","trusted":true},"outputs":[],"source":["X_train = X_train.to(device)\n","X_valid = X_valid.to(device)\n","X_test  =  X_test.to(device)\n","\n","y_train = y_train.to(device, dtype=torch.long)\n","y_valid = y_valid.to(device, dtype=torch.long)\n","y_test  =  y_test.to(device, dtype=torch.long)\n","\n","train_dataset = TensorDataset(X_train, y_train)\n","valid_dataset = TensorDataset(X_valid, y_valid)\n","test_dataset  = TensorDataset(X_test,  y_test)\n","\n","batch_size = 32\n","\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n","testloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.195637Z","iopub.status.busy":"2021-12-22T15:57:21.195452Z","iopub.status.idle":"2021-12-22T15:57:21.203430Z","shell.execute_reply":"2021-12-22T15:57:21.202474Z","shell.execute_reply.started":"2021-12-22T15:57:21.195614Z"},"id":"qXIY8Q9TDxYw","trusted":true},"outputs":[],"source":["print(len(trainloader.dataset))\n","print(len(validloader.dataset))\n","print(len(testloader.dataset))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.206003Z","iopub.status.busy":"2021-12-22T15:57:21.205433Z","iopub.status.idle":"2021-12-22T15:57:21.234729Z","shell.execute_reply":"2021-12-22T15:57:21.233831Z","shell.execute_reply.started":"2021-12-22T15:57:21.205968Z"},"id":"BkJpt-vvdr1M","trusted":true},"outputs":[],"source":["class DynamicNetInceptions(nn.Module):\n","\n","    def __init__(self, dropout_prob, conv__layer_repetitions=(1,1,1), conv__in_channels=1, conv__out_channels=(6,12,24), lin__out_dimension=(16*7*5,16,len(emotions)), incep__num_layers=4, incep__multiplier=2, im_h=im_h, im_l=im_l) :\n","      super(DynamicNetInceptions, self).__init__()\n","\n","      # PARAMETERS SECTION\n","      self.pool_size = (2,2)\n","      self.kernel_size = (3,3)\n","      self.padding = 1\n","      self.num_of_conv_layers = len(conv__layer_repetitions) # default = 3\n","      self.num_of_lin_layers = len(lin__out_dimension) # default = 3\n","      self.dropout_prob = dropout_prob\n","        \n","      self.first_dropout = nn.Dropout2d(p=self.dropout_prob[0])\n","      self.second_dropout = nn.Dropout2d(p=self.dropout_prob[1])\n","        \n","      self.skip = nn.Identity()\n","      \n","      in_chan = conv__in_channels\n","      self.convs = []\n","\n","      if (len(conv__layer_repetitions) != len(conv__out_channels)) :\n","        print(\"ERROR CHECK SIZES!!\")\n","\n","      # CONVOLUTIONAL SECTION\n","      out_chan = 0\n","      for big_layer in range(self.num_of_conv_layers) : # default = 3\n","        out_chan = conv__out_channels[big_layer]\n","        cur_rep_big_layer = conv__layer_repetitions[big_layer]\n","        for repeat_layer in range(cur_rep_big_layer) : #a, b, c, ...\n","          self.convs += [ nn.Conv2d(in_chan, out_chan, self.kernel_size, padding=self.padding) ]\n","          #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","          self.convs += [ nn.ReLU() ]\n","          in_chan = out_chan\n","        self.convs += [ nn.MaxPool2d(self.pool_size) ]\n","        #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","    \n","      #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","\n","      # INCEPTION SECTION\n","      in_chan = out_chan\n","      self.incep__multiplier = incep__multiplier\n","      self.incep__num_layers = incep__num_layers\n","      self.incep_first = self.inception_module(in_chan)\n","      self.incep_after = []\n","      total_out_chan = incep__multiplier * (64 + 128 + 32 + 32) # 256 * out_multiplier\n","      in_chan = total_out_chan\n","      for inception_layer in range(incep__num_layers - 1) :\n","          cur_incep = self.inception_module(in_chan)\n","          self.incep_after += [ cur_incep ]\n","        \n","      #self.incep_after += [ nn.Dropout2d(p=self.dropout_prob) ]\n","\n","      #final output dimension\n","      self.final_conv_dim = total_out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n","\n","      # LINEAR FC SECTION\n","      in_dim = self.final_conv_dim\n","\n","      self.linear_fc = []\n","      for lin_layer in range(self.num_of_lin_layers) :\n","        out_dim = lin__out_dimension[lin_layer]\n","        self.linear_fc += [ nn.Linear(in_dim, out_dim) ]\n","        #self.linear_fc += [ nn.Dropout2d(p=self.dropout_prob) ]\n","        self.linear_fc += [ nn.ReLU() ]\n","        in_dim = out_dim\n","      \n","      # SEQUENTIAL SECTION\n","      self.convs_seq = nn.Sequential(*self.convs).to(device)\n","      self.linear_fc_seq = nn.Sequential(*self.linear_fc).to(device)\n","      self.softmax = nn.Softmax(1).to(device)\n","\n","    def inception_module(self, in_chan, out_1x1=64, out_3x3=[96,128], out_5x5=[16,32], out_pool=32) :\n","      \n","      mul = self.incep__multiplier\n","    \n","      branch_1x1 = nn.Sequential(\n","          nn.Conv2d(in_chan, out_1x1*mul, kernel_size=1) #conv 1x1\n","      ).to(device)\n","\n","      branch_3x3 = nn.Sequential(\n","        nn.Conv2d(in_chan,          (out_3x3[0])*mul, kernel_size=1),           # conv 1x1\n","        nn.Conv2d((out_3x3[0])*mul, (out_3x3[1])*mul, kernel_size=3, padding=1) # conv 3x3\n","      ).to(device)\n","\n","      branch_5x5 =  nn.Sequential(\n","        nn.Conv2d(in_chan,          (out_5x5[0])*mul, kernel_size=1),           # conv 1x1\n","        nn.Conv2d((out_5x5[0])*mul, (out_5x5[1])*mul, kernel_size=5, padding=2) # conv 5x5\n","      ).to(device)\n","\n","      branch_pool =  nn.Sequential(\n","        nn.MaxPool2d(kernel_size=3, stride=1, padding=0), # max_pool 3x3\n","        nn.Conv2d(in_chan, out_pool*mul, kernel_size=1, stride=1, padding=1) # conv 1x1\n","      ).to(device)\n","        \n","      return [ branch_1x1, branch_3x3, branch_5x5, branch_pool ]\n","\n","    def print_net(self) :\n","        \n","      print(\"__Convolutionals Start__\")\n","      print(self.convs_seq)\n","      print(\"__Convolutionals End__\")\n","      print()\n","      \n","      print(self.first_dropout)\n","      print()\n","    \n","      print(\"__Inception Start (with skip)__\")\n","      print(\"Inception__1 with dim: N -> (256 * mul)\")\n","      print(self.incep_first)\n","      print(f\"Inception__2,...,{self.incep__num_layers} with dim: (256 * mul) -> (256 * mul)\")\n","      print(self.incep_after[0])\n","      print(\"__Inception End__\")\n","      print()\n","        \n","      #if (self.incep__num_layers > 0) :\n","      #    print(\"__Inception Start (with skip)__\")\n","      #    print(\"Inception__0:\")\n","      #    print(self.incep_first)\n","      #    for i in range(self.incep__num_layers - 1) :\n","      #        print(f\"Inception__{i+1}\")\n","      #        print(self.incep_after[i])\n","      #    print(\"__Inception End__\")\n","      #print(f\"Channel concat: torch.cat(branches)\")\n","    \n","      print(self.second_dropout)\n","      print()\n","    \n","      print(f\"Reshape(-1, {self.final_conv_dim})\")\n","      print()\n","    \n","      print(\"__Linear Start__\")\n","      print(self.linear_fc_seq)\n","      print(\"__Linear End__\")\n","      print()\n","    \n","      print(self.softmax)\n","      print()\n","\n","    def run_inception(self, x, inception) :\n","      x_1x1  = (inception[0])(x)\n","      x_3x3  = (inception[1])(x)\n","      x_5x5  = (inception[2])(x)\n","      x_pool = (inception[3])(x)\n","      concat = torch.cat((x_1x1, x_3x3, x_5x5, x_pool), 1)\n","      return concat\n","    \n","    def forward(self, x):\n","\n","      #print(x.size())\n","      x = self.convs_seq(x)\n","    \n","      x = self.second_dropout(x)\n","        \n","      #print(\"after convs\", x.size())\n","      if (self.incep__num_layers > 0) :\n","        x = self.run_inception(x, self.incep_first) \n","        #print(\"after first\", x.size()) \n","        for inception in self.incep_after : \n","          x = self.run_inception(x, inception) + self.skip(x)\n","          #print(\"after ith inception\",x.size())\n","\n","      x = self.first_dropout(x)\n","    \n","      x = x.reshape(-1, self.final_conv_dim)\n","      #print(x.size())\n","      \n","      x = self.linear_fc_seq(x)\n","      \n","      x = self.softmax(x)\n","\n","      return x\n","\n","#net = DynamicNetInceptions(0.1,conv__layer_repetitions=(2,2,1), conv__in_channels=3)\n","#net.print_net()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.241227Z","iopub.status.busy":"2021-12-22T15:57:21.240805Z","iopub.status.idle":"2021-12-22T15:57:21.257146Z","shell.execute_reply":"2021-12-22T15:57:21.255522Z","shell.execute_reply.started":"2021-12-22T15:57:21.241195Z"},"id":"jbroYNSnQqYU","trusted":true},"outputs":[],"source":["class DynamicNetBasic(nn.Module):\n","\n","    def __init__(self, dropout_prob, conv__layer_repetitions=(1,1,1), conv__in_channels=1, conv__out_channels=(6,12,24), lin__out_dimension=(16*7*5,16,len(emotions)), im_h=im_h, im_l=im_l) :\n","      super(DynamicNetBasic, self).__init__()\n","\n","      #params\n","      self.pool_size = (2,2)\n","      self.kernel_size = (3,3)\n","      self.padding = 1\n","      self.num_of_conv_layers = len(conv__layer_repetitions) # default = 3\n","      self.num_of_lin_layers = len(lin__out_dimension) # default = 3\n","      self.dropout_prob = dropout_prob\n","      \n","      in_chan = conv__in_channels\n","      self.convs = [] \n","\n","      if (len(conv__layer_repetitions) != len(conv__out_channels)) :\n","        print(\"ERROR\")\n","\n","      for big_layer in range(self.num_of_conv_layers) : # default = 3\n","        out_chan = conv__out_channels[big_layer]\n","        cur_rep_big_layer = conv__layer_repetitions[big_layer]\n","        for repeat_layer in range(cur_rep_big_layer) : #a, b, c, ...\n","          self.convs += [ nn.Conv2d(in_chan, out_chan, self.kernel_size, padding=self.padding) ]\n","          #self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","          self.convs += [ nn.ReLU() ]\n","          in_chan = out_chan\n","        self.convs += [nn.MaxPool2d(self.pool_size)]\n","\n","      self.convs += [ nn.Dropout2d(p=self.dropout_prob) ]\n","      \n","      #final output dimension\n","      self.final_conv_dim = out_chan * (im_h // (2 ** self.num_of_conv_layers)) * (im_l // (2 ** self.num_of_conv_layers))\n","\n","      # linears\n","      in_dim = self.final_conv_dim\n","\n","      self.linear_fc = []\n","      for lin_layer in range(self.num_of_lin_layers) :\n","        out_dim = lin__out_dimension[lin_layer]\n","        self.linear_fc += [ nn.Linear(in_dim, out_dim) ]\n","        #self.linear_fc += [ nn.Dropout2d(p=self.dropout_prob) ]\n","        self.linear_fc += [ nn.ReLU() ]\n","        in_dim = out_dim\n","      \n","      self.softmax = nn.Softmax(1)\n","\n","      self.features = nn.Sequential(*self.convs).to(device)\n","      self.linear_fc = nn.Sequential(*self.linear_fc).to(device)\n","\n","      #print(self.features)\n","      #print(self.linear_fc)\n","\n","    def print_net(self) :\n","      print(self.features)\n","      print(f\"Reshape(-1, {self.final_conv_dim})\")\n","      print(self.linear_fc)\n","      print(self.softmax)\n","\n","    def forward(self, x):\n","      \n","      x = self.features(x)\n","      x = x.reshape(-1, self.final_conv_dim)\n","      x = self.linear_fc(x)\n","      \n","      x = self.softmax(x)\n","\n","      return x\n","\n","#net = DynamicNetBasic(0.1,conv__layer_repetitions=(2,2,1), conv__in_channels=3)\n","#net.print_net()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.259935Z","iopub.status.busy":"2021-12-22T15:57:21.259378Z","iopub.status.idle":"2021-12-22T15:57:21.289944Z","shell.execute_reply":"2021-12-22T15:57:21.289104Z","shell.execute_reply.started":"2021-12-22T15:57:21.259883Z"},"id":"mHdagsNmyFKL","trusted":true},"outputs":[],"source":["class Optimization:\n","    def __init__(self, model, loss_fn, optimizer, schedulers=[]):\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.schedulers = schedulers\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.train_accuracies = []\n","        self.val_accuracies = []\n","    \n","    def count_preds_correct(self, y_pred, y) :\n","      preds = torch.argmax(y_pred, axis=1)\n","      count = preds.eq(y.data.view_as(preds)).cpu().sum()\n","      #print(count, preds.size(), y.size())\n","      #for i in range(preds.size()[0]) :\n","      #      print(preds[i], y[i], preds[i].eq(y[i].data.view_as(preds[i])).cpu())\n","      #print(\"end\")\n","      return count\n","    \n","    def train_step(self, x, y):\n","        #count correct predictions\n","        preds_correct = 0\n","        # Set training mode\n","        self.model.train()\n","        # Predict\n","        y_pred = self.model(x)\n","        # Computes loss, gradients\n","        #print(y.size(), y_pred.size())\n","        loss = self.loss_fn(y_pred, y)\n","        loss.backward()\n","        # Updates parameters, set to zero gradients\n","        self.optimizer.step()\n","        self.optimizer.zero_grad()\n","        # Return loss, num of correct predictions\n","        x = self.count_preds_correct(y_pred, y)\n","        preds_correct += x\n","        return loss.item(), preds_correct\n","    \n","    def train(self, train_loader, val_loader, batch_size=32, n_epochs=50, n_features=n_features, im_h=im_h, im_l=im_l):\n","        for epoch in range(n_epochs + 1):\n","            #print(f\"epoch: {epoch}\")\n","            batch_train_losses = []\n","            batch_train_accs = []\n","            train_i = 0\n","            val_i = 0\n","            train_correct = 0\n","            val_correct = 0\n","            \n","            #for x in train_loader.dataset.tensors :\n","              #print(type(x), x.get_device()) # CUDA -> 0, CPU -> -1\n","\n","            #print(\"training\")\n","            for idx, batch in enumerate(train_loader):\n","                x_batch, y_batch = batch        \n","                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n","\n","                #now = datetime.now().strftime(\"%H:%M:%S\")\n","                #print(f\"{now} epoch: {epoch}, train_i: {train_i}, val_i: {val_i}\")\n","                #x_batch = x_batch.view([cur_batch_size, -1, n_features]).to(device)\n","                cur_batch_size = len(x_batch)\n","                x_batch = x_batch.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n","                y_batch = y_batch.to(device)\n","                #print(x_batch.get_device(), y_batch.get_device())\n","                #print(f\"x_batch.size: {x_batch.size()}, y_val: {y_batch.size()}\")\n","                #cur_train_correct = 0\n","                loss, train_correct = self.train_step(x_batch, y_batch)\n","                batch_train_accs.append(train_correct / cur_batch_size)\n","                batch_train_losses.append(loss)\n","                train_i = train_i + 1\n","            train_acc = np.mean(batch_train_accs)\n","            train_loss = np.mean(batch_train_losses)\n","            self.train_accuracies.append(train_acc)\n","            self.train_losses.append(train_loss)\n","            for cur_scheduler in self.schedulers :\n","              cur_scheduler.step()\n","  \n","            #print(\"validation\")\n","            with torch.no_grad():\n","                batch_val_losses = []\n","                batch_val_accs = []\n","                for x_val, y_val in val_loader:\n","                    #now = datetime.now().strftime(\"%H:%M:%S\")\n","                    #print(f\"{now} epoch: {epoch}, train_i: {train_i}, val_i: {val_i}\")\n","                    cur_batch_size = len(x_val)\n","                    #print(f\"len(x_val): {cur_batch_size}\")\n","                    #x_val = x_val.view([cur_batch_size, -1, n_features]).to(device)\n","                    x_val = x_val.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n","                    y_val = y_val.to(device)\n","                    #print(f\"x_val.size: {x_val.size()}, y_val: {y_val.size()}\")\n","                    self.model.eval()\n","                    y_pred = self.model(x_val)\n","                    val_correct = self.count_preds_correct(y_pred, y_val)\n","                    val_loss = self.loss_fn(y_pred, y_val).item()\n","                    batch_val_acc_cur = (val_correct / cur_batch_size)\n","                    #print(val_correct, cur_batch_size, batch_val_acc_cur)\n","                    batch_val_accs.append(batch_val_acc_cur)\n","                    batch_val_losses.append(val_loss)\n","                    val_i = val_i + 1\n","                val_acc = np.mean(batch_val_accs)\n","                val_loss = np.mean(batch_val_losses)\n","                self.val_accuracies.append(val_acc)\n","                self.val_losses.append(val_loss)\n","\n","            if (epoch % 1 == 0):\n","                now = datetime.now().strftime(\"%H:%M:%S\")\n","                print(f\"{now} [{epoch:2d}/{n_epochs}] Train: [ loss: {train_loss:.8f}, acc: {train_acc:.8f} ] \\t Validation: [ loss: {val_loss:.8f}, acc: {val_acc:.8f} ]\")\n","\n","        return self.model.state_dict()\n","\n","    def evaluate(self, test_loader, batch_size=1, n_features=1, im_h=48, im_l=48):\n","        #print(\"testing\")\n","        with torch.no_grad():\n","            predictions = []\n","            real_values = []\n","            for x_test, y_test in test_loader:\n","                cur_batch_size = len(x_test)\n","                #x_test = x_test.view([cur_batch_size, -1, n_features]).to(device)\n","                x_test = x_test.view([cur_batch_size, n_features, im_h, im_l]).to(device)\n","                y_test = y_test.to(device)\n","                self.model.eval()\n","                y_pred = self.model(x_test)\n","                predictions.append(y_pred.to('cpu').detach().numpy())\n","                real_values.append(y_test.to('cpu').detach().numpy())\n","\n","        return predictions, real_values      \n","\n","    def plot_losses(self):\n","        plot.plot(self.train_losses, label=\"Training loss\")\n","        plot.plot(self.val_losses, label=\"Validation loss\")\n","        plot.legend()\n","        plot.title(\"Evolution of losses over time\")\n","        plot.xlabel(\"Epochs\")\n","        plot.ylabel(\"Losses\")\n","        plot.show()\n","        plot.close()\n","\n","    def plot_accuracies(self):\n","        plot.plot(self.train_accuracies, label=\"Training accuracy\")\n","        plot.plot(self.val_accuracies, label=\"Validation accuracy\")\n","        plot.legend()\n","        plot.title(\"Evolution of accuracies over time\")\n","        plot.xlabel(\"Epochs\")\n","        plot.ylabel(\"Accuracies\")\n","        plot.show()\n","        plot.close()\n","  \n","    def plot_losses_accuracies(self, figsize=(12,4)):\n","        fig, axs = plot.subplots(1, 2, figsize=figsize)\n","        #losses\n","        plot_1 = axs[0]\n","        plot_1.plot(self.train_losses, label=\"Training loss\")\n","        plot_1.plot(self.val_losses, label=\"Validation loss\")\n","        plot_1.legend()\n","        plot_1.set_title(\"Evolution of losses over time\")\n","        plot_1.set_xlabel(\"Epochs\")\n","        plot_1.set_ylabel(\"Losses\")\n","        #accuracies\n","        plot_2 = axs[1]\n","        plot_2.plot(self.train_accuracies, label=\"Training accuracy\")\n","        plot_2.plot(self.val_accuracies, label=\"Validation accuracy\")\n","        plot_2.legend()\n","        plot_2.set_title(\"Evolution of accuracies over time\")\n","        plot_2.set_xlabel(\"Epochs\")\n","        plot_2.set_ylabel(\"Accuracies\")\n","        "]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T15:57:21.292616Z","iopub.status.busy":"2021-12-22T15:57:21.292189Z","iopub.status.idle":"2021-12-22T15:57:21.301831Z","shell.execute_reply":"2021-12-22T15:57:21.301070Z","shell.execute_reply.started":"2021-12-22T15:57:21.292580Z"},"id":"NgcrNXxDorAR","trusted":true},"outputs":[],"source":["#R1 NO INCEPTION:\n","#n_epochs = 40\n","#learning_rate = 5e-5\n","#weight_decay = 1e-9\n","#dropout_prob = 0.35\n","\n","#dynamic net parameters\n","#conv part:\n","#conv__in_channels=n_features\n","#conv__out_channels=(288,566,1122,2244)\n","#conv__layer_repetitions=(4,3,2,1) #a=3, b=2, c=1\n","#linear part:\n","#lin__out_dimension=(1024,356,158,64,len(emotions))"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T16:02:31.428838Z","iopub.status.busy":"2021-12-22T16:02:31.428225Z","iopub.status.idle":"2021-12-22T16:02:31.432894Z","shell.execute_reply":"2021-12-22T16:02:31.432022Z","shell.execute_reply.started":"2021-12-22T16:02:31.428799Z"},"trusted":true},"outputs":[],"source":["#R2 YES INCEPTION:\n","#n_epochs = 30\n","#learning_rate = 1e-4\n","#weight_decay = 1e-8\n","#dropout_prob = 0.62\n","\n","#dynamic net parameters\n","#conv part:\n","#conv__in_channels=n_features     #num_of_channels in dataset = 3: original, \n","#conv__out_channels=     (200,400,600,800) #out channels of each conv\n","#conv__layer_repetitions=(  2,  2,  2,  1) #number of repetitions of i-th conv before go to next one, first has channels (N-1 -> N), others (N -> N)\n","#linear part:\n","#lin__out_dimension=(432, 108, 27, len(emotions)) #out dimension of fc, last one = 7\n","#inception part:\n","#incep__num_layers=30 #num of inspection modules, NB the first has shape (N -> 256*mul), others (256*mul -> 256*mul)\n","#incep__multiplier=3  #multiplier of the default out dim of resnet: (64 for 1x1, 128 per 3x3, 32 per 5x5, 32 per maxpool)\n","#NB: reshape = 256 * incep__multiplier * ((48 // (2 ** num_of_conv_layers)) ** 2) = 6912 (if mul=3, layers=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-22T16:02:31.440003Z","iopub.status.busy":"2021-12-22T16:02:31.439510Z"},"id":"pF8gbnsVybcB","trusted":true},"outputs":[],"source":["n_epochs = 30\n","learning_rate = 1e-4\n","weight_decay = 1e-8\n","#if dropout before and after inception: 25% < dropout < 30%\n","#if dropout       only after inception: 60% < dropout > 70%\n","dropout_prob = ( 0.25, 0.5 )\n","\n","#dynamic net parameters\n","#conv part:\n","conv__in_channels = n_features\n","conv__out_channels =      (288,566,1122,2244)\n","conv__layer_repetitions = (  2,  2,   1,   1)\n","#linear part:\n","lin__out_dimension = (432, 108, 27, len(emotions))\n","#inception part:\n","incep__num_layers = 35 #num of inspection modules, NB the first has shape (N -> 256*mul), others (256*mul -> 256*mul)\n","incep__multiplier =  3 #multiplier of the default out dim of resnet: (64 for 1x1, 128 per 3x3, 32 per 5x5, 32 per maxpool)\n","#NB: reshape = 256 * incep__multiplier * ((48 // (2 ** num_of_conv_layers)) ** 2) = 6912 (if mul=3, layers=4)\n","\n","model = DynamicNetInceptions(dropout_prob, conv__layer_repetitions, conv__in_channels, conv__out_channels, lin__out_dimension, incep__num_layers, incep__multiplier)\n","#model = DynamicNetBasic(dropout_prob, conv__layer_repetitions, conv__in_channels, conv__out_channels, lin__out_dimension)\n","next(model.parameters()).device\n","model.print_net()\n","\n","loss_fn = torch.nn.CrossEntropyLoss(reduction='sum') \n","#loss_fn = torch.nn.KLDivLoss(reduction='sum') \n","#loss_fn = torch.nn.NLLLoss(reduction='sum')\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","#optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n","\n","schedulers = [ \n","    lr_scheduler.ExponentialLR(optimizer, gamma=0.9),\n","    lr_scheduler.MultiStepLR(optimizer, milestones=[i for i in range(5, n_epochs, 5)], gamma=0.85),\n","]\n","\n","#train\n","opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer, schedulers=schedulers)\n","model_state_dict = opt.train(trainloader, validloader, batch_size=batch_size, n_epochs=n_epochs, n_features=n_features)\n","opt.plot_losses_accuracies() \n","#test\n","y_pred_numpy, y_test_numpy = opt.evaluate(testloader, batch_size=1, n_features=n_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWB9LNDsVYYs","trusted":true},"outputs":[],"source":["def flat_list(main_list):\n","    return [item for sub_list in main_list for item in sub_list]\n","\n","#remove batch divisions, get only predn_featuress\n","y_pred_list = [ np.argmax(item) for item in flat_list(y_pred_numpy)]\n","y_test_list = flat_list(y_test_numpy)\n","\n","num_of_emotions = len(emotions)\n","true_preds  = [ 0 for _ in range(num_of_emotions) ]\n","false_preds = [ 0 for _ in range(num_of_emotions) ]\n","\n","for i in range(len(y_test_list)) :\n","  emot_pred = y_pred_list[i]\n","  emot_real = y_test_list[i]\n","  if emot_pred == emot_real :\n","    true_preds[emot_real] += 1\n","  else :\n","    false_preds[emot_real] += 1\n","\n","accuracy = [ (true_preds[i] / (true_preds[i] + false_preds[i])) for i in range(num_of_emotions) ]\n","total_approx_acc = np.mean(accuracy)\n","total_true = np.sum(true_preds)\n","total_false = np.sum(false_preds)\n","total_real_acc = total_true / (total_true + total_false)\n","\n","analysis_df = pd.DataFrame(\n","    list(zip(list(emotions), true_preds, false_preds, accuracy)), \n","    columns=['emotions', 'true_preds', 'false_preds', 'accuracy']\n",")\n","print(f\"{total_approx_acc:.5f} mean of accuracy of each label\")\n","print(f\"{total_real_acc:.5f} accuracy of all test set\")\n","print(analysis_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl4FmZPuG1dG","trusted":true},"outputs":[],"source":["# store y_pred, y_real to df\n","y_pred_real_df = pd.DataFrame(\n","    list(zip(y_pred_list, y_test_list)), \n","    columns=['y_pred_list', 'y_test_list']\n",")\n","print(y_pred_real_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8L65IdIZj3d","trusted":true},"outputs":[],"source":["# store parameters to df\n","params_dict = {\n","    'n_epochs':                 [n_epochs],\n","    'learning_rate':            [learning_rate],\n","    'weight_decay':             [weight_decay],\n","    'dropout_prob':             [dropout_prob],\n","    'conv__in_channels':        [conv__in_channels],\n","    'conv__out_channels':       [conv__out_channels],\n","    'conv__layer_repetitions':  [conv__layer_repetitions],\n","    'lin__out_dimension':       [lin__out_dimension],\n","    'loss_fn':                  [loss_fn],\n","    'optimizer':                [optimizer.__class__.__name__],\n","    'split_seed':               [split_seed],\n","    'incep__num_layers':        [incep__num_layers],\n","    'incep__multiplier':        [incep__multiplier]\n","}\n","\n","params_df = pd.DataFrame(params_dict)\n","print(params_df.T)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TE8sq69NkEj0","trusted":true},"outputs":[],"source":["# store losses and accuracies to df\n","losses_accuracies_df = pd.DataFrame(\n","    list(zip(opt.train_losses, opt.val_losses, opt.train_accuracies, opt.val_accuracies)),\n","    columns=['train_losses', 'val_losses', 'train_accuracies', 'val_accuracies']\n",")\n","print(losses_accuracies_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOCXANlHG1dG","trusted":true},"outputs":[],"source":["import scikitplot\n","scikitplot.metrics.plot_confusion_matrix(y_pred_list, y_test_list, figsize=(7,7))\n","plot.savefig(\"confusion_matrix.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import HTML\n","import base64\n","\n","def create_download_link(df, filename, title = \"Download CSV file\"):  \n","    csv = df.to_csv(index=False)\n","    b64 = base64.b64encode(csv.encode())\n","    payload = b64.decode()\n","    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n","    html = html.format(payload=payload,title=title,filename=filename)\n","    return HTML(html)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKnQ5ZnIevrG","trusted":true},"outputs":[],"source":["#export parameters, analysis to csv file\n","now = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n","extension = '.csv'\n","\n","to_export = {\n","    \"_y_pred_real_\":       y_pred_real_df,\n","    \"_params_\" :           params_df,\n","    \"_analysis_\":          analysis_df,\n","    \"_losses_accuracies_\": losses_accuracies_df\n","}\n","\n","for name_cur, df_cur in to_export.items() :\n","    filename = (export_dir + now + name_cur + extension)\n","    df_cur.to_csv(filename, sep=';')\n","    print(f\"link of {name_cur}:\")\n","    create_download_link(df_cur, filename)\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
